{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a365c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import scipy\n",
    "from scipy.optimize import minimize, fmin\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import io\n",
    "\n",
    "import glmnet_python\n",
    "import scipy, importlib, pprint, matplotlib.pyplot as plt, warnings\n",
    "from glmnet import glmnet; from glmnetPlot import glmnetPlot \n",
    "from glmnetPrint import glmnetPrint; from glmnetCoef import glmnetCoef; from glmnetPredict import glmnetPredict\n",
    "from cvglmnet import cvglmnet; from cvglmnetCoef import cvglmnetCoef\n",
    "from cvglmnetPlot import cvglmnetPlot; from cvglmnetPredict import cvglmnetPredict\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from pyglmnet import GLM, GLMCV, datasets, utils\n",
    "\n",
    "import matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['tahoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mean, sigma):\n",
    "    return np.exp(-(x-mean)**2/(2*sigma**2))\n",
    "\n",
    "def Tones3dgrid(latentTones, sigma):    \n",
    "    \n",
    "    input_array_0 = np.expand_dims(gaussian(log_freq_percept, latentTones[0], sigma), axis = 1)\n",
    "    input_array_1 = np.expand_dims(gaussian(log_freq_percept, latentTones[1], sigma), axis = 1)\n",
    "    input_array_2 = np.expand_dims(gaussian(log_freq_percept, latentTones[2], sigma), axis = 1)\n",
    "    s0 = 1/np.sum(input_array_0); \n",
    "    s1 = 1/np.sum(input_array_1); \n",
    "    s2 = 1/np.sum(input_array_2);\n",
    "    input_array_0 *= s0; \n",
    "    input_array_1 *= s1; \n",
    "    input_array_2 *= s2; \n",
    "    \n",
    "    input_array_mat = np.expand_dims(input_array_0@input_array_1.T,axis=2)@(input_array_2.T) #p(T1,T2..|H)   \n",
    "                                     \n",
    "    return input_array_mat\n",
    "\n",
    "def posterior_array(freq_input, n_tones, p_back, p_low, log_prior):\n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "    freq_input - range of all possible frequencies (percepts?)\n",
    "    p_back - prob of background\n",
    "    p_low - prob of low condition\n",
    "    log_prior - list of prior parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    log_prior_low_mean = log_prior[0]; log_prior_low_sigma = log_prior[2];\n",
    "    log_prior_high_mean = log_prior[1]; log_prior_high_sigma = log_prior[2];\n",
    "    prior_low = gaussian(x=freq_input, mean=log_prior_low_mean, sigma=log_prior_low_sigma)\n",
    "    prior_high = gaussian(x=freq_input, mean=log_prior_high_mean, sigma=log_prior_high_sigma)\n",
    "    prior_dist_mixed_high = p_back*(1/len(freq_input)) + (1-p_back)*prior_high \\\n",
    "    #mixture model with p(T|B) = 1/no. of possible freqs\n",
    "    prior_dist_mixed_high /= prior_dist_mixed_high.sum() #normalizing\n",
    "    prior_dist_mixed_high = np.expand_dims(prior_dist_mixed_high, axis = 1)\n",
    "    prior_dist_mixed_low = p_back*(1/len(freq_input)) + (1-p_back)*prior_low \\\n",
    "    #mixture model with p(T|B) = 1/no. of possible freqs\n",
    "    prior_dist_mixed_low /= prior_dist_mixed_low.sum() #normalizing\n",
    "    prior_dist_mixed_low = np.expand_dims(prior_dist_mixed_low, axis = 1)\n",
    "        \n",
    "    if n_tones == 3:\n",
    "        prior_tones_low = np.expand_dims(prior_dist_mixed_low@np.transpose\\\n",
    "                                         (prior_dist_mixed_low),axis=2)@np.transpose(prior_dist_mixed_low) \\\n",
    "        #p(T1,T2..|L) \n",
    "        \n",
    "        prior_tones_high = np.expand_dims(prior_dist_mixed_high@np.transpose\\\n",
    "                                          (prior_dist_mixed_high),axis=2)@np.transpose(prior_dist_mixed_high) \\\n",
    "        #p(T1,T2..|H) \n",
    "\n",
    "    elif n_tones == 1:\n",
    "        prior_tones_low = prior_dist_mixed_low\n",
    "        prior_tones_high = prior_dist_mixed_high\n",
    "        \n",
    "    normalizer = (1-p_low)*prior_tones_high + p_low*prior_tones_low #p(H)*p(T1,T2..|H) + p(L)*p(T1,T2..|L)\n",
    "    posterior = prior_tones_high*(1-p_low)/normalizer\n",
    "    # posterior /= np.sum(posterior)\n",
    "    \n",
    "    return prior_dist_mixed_high, prior_dist_mixed_low, prior_tones_high, prior_tones_low, normalizer, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_prior_covariance(sigma_tonal=3.):\n",
    "        '''Design a prior covariance matrix for STRF estimation.\n",
    "        Args:\n",
    "            sigma_temporal (float): Standard deviation of temporal prior\n",
    "                covariance.\n",
    "            sigma_spatial (float): Standard deviation of spatial prior\n",
    "                covariance.\n",
    "        Returns:\n",
    "            numpy array: 2-d array of size :data:`(n_spatial_basis *\n",
    "            n_temporal_basis, n_spatial_basis * n_temporal_basis)`, the\n",
    "            ordering of rows and columns is so that all temporal basis are\n",
    "            consecutive for each spatial basis.\n",
    "        '''\n",
    "\n",
    "        freq_seq = np.arange(90,3000,1) #array of possible true tones\n",
    "        log_freq_seq_array = np.arange(np.log10(freq_seq[0]), np.log10(freq_seq[-1]), np.log10(1003/1000)*40)\n",
    "        n_features = len(log_freq_seq_array)\n",
    "        \n",
    "        tonal_covariance = np.zeros([n_features, n_features])\n",
    "        prior_covariance = np.zeros([n_features, n_features])\n",
    "        for i in np.arange(0, n_features):\n",
    "            for j in np.arange(i, n_features):\n",
    "                tonal_covariance[i, j] = np.exp(-1. / (sigma_tonal ** 2) *\n",
    "                                             (log_freq_seq_array[i] - log_freq_seq_array[j]) ** 2)\n",
    "                tonal_covariance[j, i] = tonal_covariance[i, j]\n",
    "\n",
    "        prior_covariance = tonal_covariance\n",
    "        prior_covariance = 1. / np.max(prior_covariance) * prior_covariance\n",
    "        return prior_covariance\n",
    "    \n",
    "\n",
    "prior_cov = design_prior_covariance(sigma_tonal = 2)\n",
    "\n",
    "plt.imshow(prior_cov, cmap='Greys', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35684e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Obtaining data from a given expt\n",
    "\"\"\"\n",
    "Test = pd.read_csv('../auditory_categorization_noContext/important_things_not_included_in_assets/allTrials.csv')\n",
    "Data = pd.read_csv('auditory_categorization_prolific_online_data/human_auditory_categorization_91686_2022-01-19_20h56.51_f8da6647-2fb7-444d-9e8c-e52b3a37d4b2/5ea1f4fa7a70090fd0715b34_categorization_task_2021-03-01_18h06.17.396.csv');\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(csv_test, csv_data, exptTotalLength, exptLengthWithBreaks):   \n",
    "    n_trials = csv_data.shape[0]-47\n",
    "\n",
    "    test_columns = list(csv_test.columns)\n",
    "    test_tones_name = test_columns.index('Name')\n",
    "    test_tones_col_idx = test_columns.index('Tones')\n",
    "    df_names = (csv_test.iloc[0:exptTotalLength,test_tones_name]).values\n",
    "    df_tones = (csv_test.iloc[0:exptTotalLength,test_tones_col_idx]).values\n",
    "\n",
    "    tones_array_orig = np.zeros((n_trials,n_tones))\n",
    "    tones_array_idxs_keep = []\n",
    "\n",
    "    for i_wav in range(exptLengthWithBreaks):\n",
    "        if isinstance(csv_data['Name'][i_wav+46],str):\n",
    "            tones_array_orig[i_wav,:] = np.array(df_tones[np.where(csv_data['Name'][i_wav+46]\\\n",
    "                                                              ==df_names)[0]][0][1:-1].split(',')).astype(float)  \n",
    "            tones_array_idxs_keep += [i_wav]\n",
    "\n",
    "\n",
    "    exptTones = np.copy(tones_array_orig[tones_array_idxs_keep,:])\n",
    "    exptCorrans = np.copy(csv_data['corrAns'][46:csv_data.shape[0]])[tones_array_idxs_keep]\n",
    "    exptKeys = np.copy(csv_data['test_resp.keys'][46:csv_data.shape[0]])[tones_array_idxs_keep]\n",
    "    \n",
    "    return exptTones, exptCorrans, exptKeys\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tones = 3\n",
    "\n",
    "\"\"\"\n",
    "Get tones and values of keys pressed from no context expt\n",
    "\"\"\"\n",
    "df_tones, df_corrans, df_keys = extractData(csv_test=Test, \n",
    "                                            csv_data=Data, \n",
    "                                            exptTotalLength=600, \n",
    "                                            exptLengthWithBreaks=603)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyResponseTrials(keysPressed, correctAns, tonesPlayed, exptTotalLength):\n",
    "    no_response = np.intersect1d(np.where(keysPressed!='h')[0],\n",
    "                                 np.where(keysPressed!='l')[0])\n",
    "    print(\"Did not respond to: \",no_response)\n",
    "\n",
    "    \"\"\"\n",
    "    Convert keys ['l','h'] to [0,1]\n",
    "    \"\"\"\n",
    "\n",
    "    corrans_num_orig = np.zeros_like(correctAns)\n",
    "    corrans_num_orig[correctAns == 'h'] = 1\n",
    "\n",
    "    keys_num_orig = np.zeros_like(keysPressed)\n",
    "    keys_num_orig[keysPressed == 'h'] = 1\n",
    "\n",
    "    corrans_num = corrans_num_orig[:exptTotalLength]\n",
    "    keys_num = keys_num_orig[:exptTotalLength]\n",
    "    tones_array = tonesPlayed[:exptTotalLength]\n",
    "    print(\"Got correct: \", np.sum(keys_num==corrans_num)/len(tones_array))\n",
    "    print(\"No. of minority category correct: \", np.sum(keys_num*corrans_num)/np.sum(corrans_num))\n",
    "\n",
    "    trial_tones = np.repeat(tones_array,1,axis = 0)\n",
    "    trial_behaviour = np.reshape(keys_num,np.prod(keys_num.shape)) \n",
    "    idxs_with_response = np.delete(np.arange(len(trial_tones)),no_response)\n",
    "    trialTonesResponded = trial_tones[idxs_with_response,:]\n",
    "    trialBehaviourResponded = trial_behaviour[idxs_with_response]\n",
    "    corransResponded = corrans_num[idxs_with_response]\n",
    "    print(f\"Total trials played are {len(trial_tones)}, and total trials responded to are {len(trialTonesResponded)}\")\n",
    "    \n",
    "    return trialTonesResponded, trialBehaviourResponded, corransResponded\n",
    "\n",
    "\"\"\"\n",
    "Find no response cases in the no context expt\n",
    "\"\"\"\n",
    "trial_tones_expt, trial_behaviour_expt, corrans_expt = identifyResponseTrials(keysPressed = df_keys, \n",
    "                                                                            correctAns = df_corrans, \n",
    "                                                                            tonesPlayed = df_tones, \n",
    "                                                                            exptTotalLength = 600)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eebdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_tones = np.arange(90,3000,1) #array of possible true tones\n",
    "log_freq_seq_array = np.arange(0.6,4.7,0.1)\n",
    "log_freq_percept = np.arange(0.6,4.7,0.1) # array of possible perceptual tones\n",
    "\n",
    "def betaValuesSim(tones_array,keys_num,\n",
    "                  alpha,noTau, \n",
    "                  permutations):\n",
    "    \n",
    "    glmBetas = np.zeros((permutations,31))\n",
    "    betas = np.zeros((permutations,31))\n",
    "    GLMScoreTt = 0\n",
    "    PyGLMScoreTt = 0\n",
    "    \n",
    "    kf = KFold(n_splits=permutations)\n",
    "    nn = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(tones_array):\n",
    "        # print(\"TEST:\", test_index)\n",
    "        Xtrain, Xtest = tones_array[train_index,:], tones_array[test_index,:]\n",
    "        ytrain, ytest = keys_num[train_index], keys_num[test_index]\n",
    "    \n",
    "        \"\"\"\n",
    "        Train Variables\n",
    "        \"\"\"\n",
    "        trial_tonesTr = np.repeat(Xtrain,1,axis = 0)\n",
    "        trial_behaviourTr = np.reshape(ytrain,np.prod(ytrain.shape)) \n",
    "\n",
    "        \"\"\"\n",
    "        Creating lookup table\n",
    "        \"\"\"\n",
    "        uniqueTonesTr = np.unique(tones_array)\n",
    "        freqTableTr = np.zeros((len(trial_tonesTr),len(uniqueTonesTr)))\n",
    "        for ii in range(len(trial_tonesTr)):\n",
    "            for jj in trial_tonesTr[ii]:\n",
    "                freqTableTr[ii,np.where(uniqueTonesTr==jj)] += 1        \n",
    "\n",
    "        \"\"\"\n",
    "        Test Variables\n",
    "        \"\"\"\n",
    "        trial_tonesTt = np.repeat(Xtest,1,axis = 0)\n",
    "        trial_behaviourTt = np.reshape(ytest,np.prod(ytest.shape)) \n",
    "\n",
    "        \"\"\"\n",
    "        Creating lookup table\n",
    "        \"\"\"\n",
    "        uniqueTonesTt = np.unique(tones_array)\n",
    "        freqTableTt = np.zeros((len(trial_tonesTt),len(uniqueTonesTt)))\n",
    "        for ii in range(len(trial_tonesTt)):\n",
    "            for jj in trial_tonesTt[ii]:\n",
    "                freqTableTt[ii,np.where(uniqueTonesTt==jj)] += 1       \n",
    "\n",
    "        \"\"\"\n",
    "        Cross-validation using glmnet\n",
    "        \"\"\"\n",
    "        #plt.figure()\n",
    "        cvfit = cvglmnet(x = freqTableTr, y = trial_behaviourTr.astype(float),\n",
    "                         family = 'binomial', ptype = 'class', alpha=alpha)\n",
    "        \"\"\"\n",
    "        Results of fit\n",
    "        \"\"\"\n",
    "        #cvglmnetPlot(cvfit)\n",
    "        betas[nn] = cvglmnetCoef(cvfit, s='lambda_min').flatten()\n",
    "        GLMScoreTt += sum(cvglmnetPredict(cvfit, newx=freqTableTt, s='lambda_min', ptype='class').flatten()\n",
    "                          ==trial_behaviourTt)/len(trial_behaviourTt)\n",
    "\n",
    "        \"\"\"\n",
    "        Cross-validation using pyglmnet\n",
    "        \"\"\"\n",
    "\n",
    "        n_samples = freqTableTr.shape[0]\n",
    "        \"\"\"\n",
    "        tau possibilities \n",
    "        \"\"\"\n",
    "        #Tau = utils.tikhonov_from_prior(prior_cov, n_samples)\n",
    "\n",
    "        Tau = np.zeros((len(uniqueTonesTr),len(uniqueTonesTr)))\n",
    "        for ii in range(len(uniqueTonesTr)):\n",
    "            Tau[ii,ii] = 2\n",
    "            if ii < len(uniqueTonesTr)-1:\n",
    "                Tau[ii,ii+1] = -0.5-1\n",
    "            if ii > 0:\n",
    "                Tau[ii,ii-1] = -0.5\n",
    "\n",
    "        # use the default value for reg_lambda\n",
    "        glm = GLMCV(distr='binomial', alpha=alpha, Tau=(1-noTau)*Tau[1:-1,:], score_metric='accuracy',tol=1e-4,\n",
    "                   max_iter=3000)\n",
    "                \n",
    "        # fit model\n",
    "        glm.fit(freqTableTr, trial_behaviourTr.astype(float))\n",
    "\n",
    "        # score the test set prediction\n",
    "        #print(\"PyGLMNet train score: %f\" % glm.score(freqTableTr, trial_behaviourTr))\n",
    "        PyGLMScoreTt += glm.score(freqTableTt, trial_behaviourTt)\n",
    "\n",
    "        glmBetas[nn,0] = glm.beta0_\n",
    "        glmBetas[nn,1:] = glm.beta_\n",
    "        \n",
    "        nn+=1\n",
    "    \n",
    "    print(alpha, [GLMScoreTt/permutations, PyGLMScoreTt/permutations])\n",
    "    \n",
    "    return(uniqueTonesTr, betas, np.array(glmBetas), GLMScoreTt/permutations, PyGLMScoreTt/permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed0cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparing both contexts for simulated behaviour\n",
    "\"\"\"\n",
    "GLMscore_no = np.zeros((11,1))\n",
    "PyGLMscore_no = np.zeros((11,1))\n",
    "GLMscore_v2_no = np.zeros((11,1))\n",
    "PyGLMscore_v2_no = np.zeros((11,1))\n",
    "\n",
    "for ialpha in range(0,11):\n",
    "    [uniqueTonesSmall_v2, betasSmall_v2_no, pyGLMbetasSmall_v2_no,\n",
    "    GLMscore_v2_no[ialpha], PyGLMscore_v2_no[ialpha]] = betaValuesSim(trial_tones_expt,\n",
    "                                                                 trial_behaviour_expt,\n",
    "                                                                 alpha = ialpha*0.1,\n",
    "                                                                 noTau=0, \n",
    "                                                                 permutations=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-brand",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots that decide the correct alpha\n",
    "\"\"\"\n",
    "#plt.figure()\n",
    "#plt.plot(range(0,11),PyGLMscore_v2_no, 'blue')\n",
    "\n",
    "[uniqueTonesSmall_v2, betasSmall_v2_no, \n",
    " pyGLMbetasSmall_v2_no,s1_no,s2_no] = betaValuesSim(trial_tones_expt,\n",
    "                                                  trial_behaviour_expt,\n",
    "                                                  alpha = 0,#np.argmax(PyGLMscore_v2_no )*0.1,\n",
    "                                                  noTau=0, \n",
    "                                                  permutations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6b75e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots that check for smoothing due to tikhonov\n",
    "\"\"\"\n",
    "#print('alpha',(np.argmax(cumulativeScore))*0.1)\n",
    "print('glm scores for no context',s1_no, s2_no)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "meanShift_no = np.mean(np.mean(pyGLMbetasSmall_v2_no[:,1:],axis=0))\n",
    "glmWeights_no = np.mean(pyGLMbetasSmall_v2_no[:,1:],axis=0)-meanShift_no\n",
    "plt.errorbar(np.log10(uniqueTonesSmall_v2),\n",
    "             glmWeights_no, \n",
    "             np.std(pyGLMbetasSmall_v2_no[:,1:],axis=0)/np.sqrt(10), \n",
    "             color='black', ls='--',linewidth=2)\n",
    "bias_no = np.mean(pyGLMbetasSmall_v2_no[:,0]) + 3*meanShift_no\n",
    "\n",
    "print(\"Norm of distractor weights compared to norm of all weights no context\",\n",
    "      (sum(np.abs(glmWeights_no[:8]))+sum(np.abs(glmWeights_no[-8:])))/sum(np.abs(glmWeights_no)))\n",
    "\n",
    "print(f\"Bias terms no : {bias_no}\")\n",
    "ax.set_xticks(ticks=np.log10([100,1000,3000]))\n",
    "ax.set_xticklabels([100,1000,3000])\n",
    "ax.set_yticks(ticks=np.array([1,0,-1]))\n",
    "ax.set_yticklabels(np.array([1,0,-1]))\n",
    "ax.tick_params(axis='both',labelsize=26,length=6,width=2)\n",
    "ax.set_xlabel('Frequency (Hz)',fontsize=26)\n",
    "ax.set_ylabel('GLM weights',fontsize=26)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "#plt.title(f'Pyglmnet elastic net with Tikhonov smoothing, alpha = {(np.argmax(cumulativeScore))*0.1}')\n",
    "pd.DataFrame(glmWeights_no).to_csv(\"figures/FromProlific/glms/glmsAcrossNoContext/5b34_noContext_GLMWeights.csv\")\n",
    "plt.savefig('figures/FromProlific/glms/glmsAcrossNoContext/experimenter=5b34_cleaner_modelfit.eps',\n",
    "           bbox_inches='tight',format='eps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb914ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecc8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import scipy\n",
    "from scipy.optimize import minimize, fmin\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8387087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Obtaining data from a given expt\n",
    "\"\"\"\n",
    "csv_test = pd.read_csv('../auditory_categorization_longLow/important_things_not_included_in_assets/allTrials.csv')\n",
    "csv_data = pd.read_csv('auditory_categorization_lc_online_data/auditory_categorization_v2_119865_2021-10-07_14h10.37_f5bf4a3a-1cbd-4b5c-9de5-23da829018ed/5f3990fea9ef865370ac735a_categorization_task_longLow_2021-04-19_17h09.03.462.csv');\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7702631",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tones = 3\n",
    "n_trials = csv_data.shape[0]-47\n",
    "\n",
    "\"\"\"\n",
    "Get tones and values of keys pressed\n",
    "\"\"\"\n",
    "test_columns = list(csv_test.columns)\n",
    "test_tones_name = test_columns.index('Name')\n",
    "test_tones_col_idx = test_columns.index('Tones')\n",
    "df_names = (csv_test.iloc[0:800,test_tones_name]).values\n",
    "df_tones = (csv_test.iloc[0:800,test_tones_col_idx]).values\n",
    "\n",
    "tones_array_orig = np.zeros((n_trials,n_tones))\n",
    "tones_array_idxs_keep = []\n",
    "\n",
    "for i_wav in range(804):\n",
    "    if isinstance(csv_data['Name'][i_wav+46],str):\n",
    "        tones_array_orig[i_wav,:] = np.array(df_tones[np.where(csv_data['Name'][i_wav+46]\\\n",
    "                                                          ==df_names)[0]][0][1:-1].split(',')).astype(float)  \n",
    "        tones_array_idxs_keep += [i_wav]\n",
    "\n",
    "        \n",
    "df_tones = np.copy(tones_array_orig[tones_array_idxs_keep,:])\n",
    "df_corrans = np.copy(csv_data['corrAns'][46:csv_data.shape[0]])[tones_array_idxs_keep]\n",
    "df_keys = np.copy(csv_data['test_resp.keys'][46:csv_data.shape[0]])[tones_array_idxs_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc326e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not respond to:  []\n",
      "Got correct:  0.85375\n",
      "Got high correct:  0.847457627118644\n",
      "Got low correct:  0.8563829787234043\n",
      "Majority category accuracy - minority category accuracy -0.008925351604760268\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find no response cases in the expt\n",
    "\"\"\"\n",
    "no_response = np.intersect1d(np.where(df_keys!='h')[0],np.where(df_keys!='l')[0])\n",
    "print(\"Did not respond to: \",no_response)\n",
    "\n",
    "\"\"\"\n",
    "Convert keys ['l','h'] to [0,1] and plot p(H|T)\n",
    "\"\"\"\n",
    "corrans_num_orig = np.zeros_like(df_corrans)\n",
    "corrans_num_orig[df_corrans == 'h'] = 1\n",
    "\n",
    "keys_num_orig = np.zeros_like(df_keys)\n",
    "keys_num_orig[df_keys == 'h'] = 1\n",
    "\n",
    "corrans_num = corrans_num_orig[:800]\n",
    "keys_num = keys_num_orig[:800]\n",
    "tones_array = df_tones[:800]\n",
    "print(\"Got correct: \", np.sum(keys_num==corrans_num)/len(tones_array))\n",
    "print(\"Got high correct: \", np.sum((keys_num)*(corrans_num))/np.sum(corrans_num))\n",
    "print(\"Got low correct: \", np.sum((1-keys_num)*(1-corrans_num))/np.sum(1-corrans_num))\n",
    "print(\"Majority category accuracy - minority category accuracy\",\n",
    "      -np.sum((1-keys_num)*(1-corrans_num))/np.sum(1-corrans_num)\n",
    "      +np.sum((keys_num)*(corrans_num))/np.sum(corrans_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6d700a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8,\n",
       "        1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. , 3.1,\n",
       "        3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4. , 4.1, 4.2, 4.3, 4.4,\n",
       "        4.5, 4.6]),\n",
       " (41,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_tones = np.repeat(tones_array,1,axis = 0)\n",
    "trial_behaviour = np.reshape(keys_num,np.prod(keys_num.shape)) \n",
    "# this has been changed to check how values change with observer responses\n",
    "\n",
    "expt_tones = np.arange(90,3000,1) #array of possible true tones\n",
    "log_freq_seq_array = np.arange(0.6,4.7,0.1)\n",
    "log_freq_percept = np.arange(0.6,4.7,0.1) # array of possible perceptual tones\n",
    "\n",
    "idxs_with_response = np.delete(np.arange(len(trial_tones)),no_response)\n",
    "trial_tones = trial_tones[idxs_with_response,:]\n",
    "trial_behaviour = trial_behaviour[idxs_with_response]\n",
    "\n",
    "log_freq_percept, log_freq_seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4554bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mean, sigma):\n",
    "    return np.exp(-(x-mean)**2/(2*sigma**2))\n",
    "\n",
    "def Tones3dgrid(latentTones, sigma):    \n",
    "    \n",
    "    input_array_0 = np.expand_dims(gaussian(log_freq_percept, latentTones[0], sigma), axis = 1)\n",
    "    input_array_1 = np.expand_dims(gaussian(log_freq_percept, latentTones[1], sigma), axis = 1)\n",
    "    input_array_2 = np.expand_dims(gaussian(log_freq_percept, latentTones[2], sigma), axis = 1)\n",
    "    s0 = 1/np.sum(input_array_0); \n",
    "    s1 = 1/np.sum(input_array_1); \n",
    "    s2 = 1/np.sum(input_array_2);\n",
    "    input_array_0 *= s0; \n",
    "    input_array_1 *= s1; \n",
    "    input_array_2 *= s2; \n",
    "    \n",
    "    input_array_mat = np.expand_dims(input_array_0@input_array_1.T,axis=2)@(input_array_2.T) #p(T1,T2..|H)   \n",
    "                                     \n",
    "    return input_array_mat\n",
    "\n",
    "def posterior_array(freq_input, n_tones, p_low, log_prior):\n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "    freq_input - range of all possible frequencies (percepts?)\n",
    "    p_back - prob of background\n",
    "    p_low - prob of low condition\n",
    "    log_prior - list of prior parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    log_prior_low_mean = log_prior[0]; log_prior_low_sigma = log_prior[2];\n",
    "    log_prior_high_mean = log_prior[1]; log_prior_high_sigma = log_prior[2];\n",
    "    prior_low = gaussian(x=freq_input, mean=log_prior_low_mean, sigma=log_prior_low_sigma)\n",
    "    prior_high = gaussian(x=freq_input, mean=log_prior_high_mean, sigma=log_prior_high_sigma)\n",
    "    prior_tones_low = np.zeros((len(freq_input), len(freq_input), len(freq_input)))\n",
    "    prior_tones_high = np.zeros_like(prior_tones_low)\n",
    "    \n",
    "    if n_tones == 3:\n",
    "        for iFreq1 in range(len(freq_input)):\n",
    "            for iFreq2 in range(len(freq_input)):\n",
    "                for iFreq3 in range(len(freq_input)):\n",
    "                    prior_tones_low[iFreq1,iFreq2,iFreq3] = (prior_low[iFreq1]*prior_low[iFreq2]+\n",
    "                                                             prior_low[iFreq2]*prior_low[iFreq3]+\n",
    "                                                             prior_low[iFreq1]*prior_low[iFreq3])/3\n",
    "                    prior_tones_high[iFreq1,iFreq2,iFreq3] = (prior_high[iFreq1]*prior_high[iFreq2]+\n",
    "                                                             prior_high[iFreq2]*prior_high[iFreq3]+\n",
    "                                                             prior_high[iFreq1]*prior_high[iFreq3])/3\n",
    "    prior_tones_low /= prior_tones_low.sum() #normalizing\n",
    "    prior_tones_high /= prior_tones_high.sum()\n",
    "        \n",
    "    normalizer = (1-p_low)*prior_tones_high + p_low*prior_tones_low #p(H)*p(T1,T2..|H) + p(L)*p(T1,T2..|L)\n",
    "    posterior = prior_tones_high*(1-p_low)/normalizer\n",
    "    # posterior /= np.sum(posterior)\n",
    "    \n",
    "    return prior_tones_high, prior_tones_low, normalizer, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6186cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mle function\n",
    "def MLE(params):\n",
    "    log_prior_low_mean, log_prior_high_mean, log_prior_sigma, sigma_sensory, prob_low = \\\n",
    "    params[0], params[1], params[2], params[3], params[4] # inputs are guesses at our parameters  \n",
    "    \n",
    "    LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow,_,_ = \\\n",
    "    posterior_array(log_freq_seq_array, n_tones=len(trial_tones[0]), p_low=prob_low,\\\n",
    "                    log_prior=[log_prior_low_mean,log_prior_high_mean,log_prior_sigma])\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    \n",
    "    for itrue1 in range(len(log_freq_seq_array)):\n",
    "        for itrue2 in range(len(log_freq_seq_array)):            \n",
    "            for itrue3 in range(len(log_freq_seq_array)):\n",
    "                probPerceptgivenLatentTones = Tones3dgrid([log_freq_seq_array[itrue1],\\\n",
    "                                                           log_freq_seq_array[itrue2],\\\n",
    "                                                           log_freq_seq_array[itrue3]],sigma=sigma_sensory)                                                           \n",
    "                LikelihoodPerceptgivenHigh \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                LikelihoodPerceptgivenLow \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*(prob_low))\n",
    "        \n",
    "    neg_ll = 0; \n",
    "    probability_high = np.zeros((len(trial_tones),1))\n",
    "    for i_trial in range(len(trial_tones)):\n",
    "        input_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_trial][0]),\\\n",
    "                                               np.log10(trial_tones[i_trial][1]),\n",
    "                                               np.log10(trial_tones[i_trial][2])]),sigma=sigma_sensory)\n",
    "        probability_high0 = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "        probability_high[i_trial] = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "            \n",
    "        if trial_behaviour[i_trial]:\n",
    "            if np.isnan(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isnan(np.log(1-probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(1-probability_high0 + 0.0000001)):\n",
    "                pdb.set_trace()\n",
    "            neg_ll += -np.log(probability_high0 + 0.0000001) # if high dist is chosen by observer\n",
    "        else:\n",
    "            neg_ll += -np.log(1 - probability_high0 + 0.0000001) # if low dist is chosen by observer\n",
    "    return(neg_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ef4f6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ec5d9351ca4955835d08f4c839a516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-125629ffb5eb>:50: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior = prior_tones_high*(1-p_low)/normalizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "New optimization algorithm: uses scipy.optimize.fmin. \n",
    "Crude grid initially and then find minimum using the function.\n",
    "\"\"\"\n",
    "\n",
    "guess_low_mean = np.arange(2.1,2.71,0.15); guess_high_mean = np.arange(2.7,3.31,0.15); \n",
    "guess_sigma = np.arange(0.05,1,0.2); guess_sensory_sigma = np.asarray([0.15]);\n",
    "guess_p_low = np.arange(0.6,0.81,0.05)\n",
    "\n",
    "# Constraining guesses of means of low and high distributions based on observed behaviour in figure shown above. \n",
    "\n",
    "neg_ll_array = np.zeros((len(guess_low_mean), len(guess_high_mean),\n",
    "                         len(guess_sigma), len(guess_sensory_sigma), \n",
    "                         len(guess_p_low)))\n",
    "for lm in tqdm(range(len(guess_low_mean))):\n",
    "    for hm in tqdm(range(len(guess_high_mean)), leave=False, desc=\"High mean\"):\n",
    "        for s in range(len(guess_sigma)):\n",
    "            for ss in range(len(guess_sensory_sigma)):\n",
    "                for pl in range(len(guess_p_low)):\n",
    "                    params = [guess_low_mean[lm], guess_high_mean[hm], guess_sigma[s], \\\n",
    "                              guess_sensory_sigma[ss], guess_p_low[pl]]\n",
    "                        # print(lm, hm, pb)\n",
    "                    neg_ll_array[lm,hm,s,ss,pl] = MLE(params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attempted-greeting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.55]\n",
      " [2.85]\n",
      " [0.05]\n",
      " [0.15]\n",
      " [0.6 ]] 287.05975723895426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-125629ffb5eb>:50: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior = prior_tones_high*(1-p_low)/normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.55 2.85 0.05 0.15 0.6 ] 287.05975723895426\n",
      "[2.6775 2.85   0.05   0.15   0.6   ] 337.99397833233127\n",
      "[2.55   2.9925 0.05   0.15   0.6   ] 335.3570255296126\n",
      "[2.55   2.85   0.0525 0.15   0.6   ] 287.05975723895426\n",
      "[2.55   2.85   0.05   0.1575 0.6   ] 287.19601529837064\n",
      "[2.55 2.85 0.05 0.15 0.63] 289.17456884064546\n",
      "[2.4225 2.907  0.051  0.153  0.612 ] 309.20987300450054\n",
      "[2.499  2.7303 0.0514 0.1542 0.6168] 332.9469465770935\n",
      "[2.51175 2.79585 0.05105 0.15315 0.6126 ] 298.18189393060123\n",
      "[2.6622  2.77134 0.05042 0.15126 0.60504] 318.890639802987\n",
      "[2.482425 2.873085 0.050855 0.152565 0.61026 ] 298.67569869480633\n",
      "[2.602275 2.805255 0.050565 0.151695 0.60678 ] 285.0149955599854\n",
      "[2.6622  2.77134 0.05042 0.15126 0.60504] 318.89063980298704\n",
      "[2.60916  2.886252 0.050176 0.150528 0.602112] 301.1623775318271\n",
      "[2.5361025 2.8184505 0.0508315 0.1524945 0.609978 ] 292.68791240584767\n",
      "[2.5848075 2.8636515 0.0503945 0.1511835 0.604734 ] 295.3651622652714\n",
      "[2.54827875 2.82975075 0.05072225 0.15216675 0.608667  ] 285.2113100583912\n",
      "[2.5702215 2.8240023 0.0515149 0.1545447 0.5761788] 284.1267510317618\n",
      "[2.58033225 2.81100345 0.05227235 0.15681705 0.5492682 ] 283.6174038992744\n",
      "[2.5823544  2.80840368 0.05242384 0.14677152 0.58588608] 283.29970830225614\n",
      "[2.5985316  2.78760552 0.05363576 0.14140728 0.57882912] 282.79136310957324\n",
      "[2.60176704 2.78344589 0.05037814 0.15083443 0.57741773] 282.3154183668148\n",
      "[2.62765056 2.75016883 0.04931722 0.15125165 0.56612659] 282.54900841345625\n",
      "[2.62247386 2.75682424 0.0530294  0.1511682  0.56838482] 282.005255262374\n",
      "[2.65871078 2.71023636 0.0545441  0.15175231 0.55257723] 296.42969097173375\n",
      "[2.65387315 2.74790289 0.05323001 0.14860204 0.54360495] 282.5511169069357\n",
      "[2.62051616 2.7494578  0.05445327 0.1478366  0.52022193] 294.55039291982274\n",
      "[2.60683529 2.7913057  0.05153707 0.1507304  0.58514048] 283.1645216980779\n",
      "[2.65306012 2.73583025 0.0524518  0.14027989 0.59208264] 306.1396944154295\n",
      "[2.59851422 2.79221015 0.05231721 0.15268276 0.55997181] 282.27182921873117\n",
      "[2.62322866 2.75588978 0.05349915 0.14714749 0.54614289] 281.60468869596775\n",
      "[2.63142534 2.73818182 0.05448019 0.14535603 0.52664409] 292.71388553853194\n",
      "[2.64141117 2.74690366 0.05134581 0.15876669 0.53937976] 282.36225850595366\n",
      "[2.58108483 2.7862066  0.05099787 0.15563779 0.57291385] 283.57604489448596\n",
      "[2.63567607 2.75747882 0.05267198 0.15036098 0.55093217] 282.04434109248024\n",
      "[2.59125277 2.79143589 0.05341255 0.14211086 0.58176001] 283.22075618150984\n",
      "[2.62887157 2.75803672 0.05186249 0.15460273 0.54997482] 282.16881826834356\n",
      "[2.64173871 2.74472999 0.05497395 0.15155043 0.53274488] 281.0064426601552\n",
      "[2.66172454 2.72537205 0.05727185 0.15190843 0.51040845] 281.56837707718825\n",
      "[2.66228132 2.71697367 0.05409757 0.14924917 0.53930002] 285.361104670279\n",
      "[2.61445599 2.77340103 0.0527623  0.15182436 0.55480386] 281.67765847218635\n",
      "[2.62615774 2.75729283 0.05491222 0.14621785 0.55122863] 281.0421771522168\n",
      "[2.61554591 2.75777633 0.05499883 0.14880236 0.55038986] 282.86136354066355\n",
      "[2.63064353 2.7575532  0.05325369 0.14997132 0.55079659] 281.64291327878925\n",
      "[2.632016   2.75872249 0.05473112 0.14751638 0.52590192] 281.15578253058976\n",
      "[2.64705786 2.73627428 0.05578575 0.14513702 0.5279221 ] 280.3667384770152\n",
      "[2.66335879 2.71771091 0.05729747 0.14179335 0.51448122] 279.48994187043314\n",
      "[2.64395643 2.7361852  0.05691187 0.14371888 0.51740322] 290.9776020635025\n",
      "[2.63397175 2.7522112  0.05416824 0.14840821 0.54244825] 280.96764758017605\n",
      "[2.65566854 2.73637719 0.05693405 0.14704701 0.52057907] 280.48446510860254\n",
      "[2.65634222 2.72460636 0.05658325 0.14649037 0.5386909 ] 282.62420531406684\n",
      "[2.63809755 2.75019345 0.05519415 0.14725987 0.52909916] 281.14843630890584\n",
      "[2.65026066 2.73313539 0.05612022 0.14674687 0.53549365] 280.4477155396139\n",
      "[2.67184164 2.71637304 0.05688535 0.14800049 0.5070702 ] 281.1797601572119\n",
      "[2.63757872 2.74706288 0.0554055  0.14666351 0.54018902] 280.8970357437016\n",
      "[2.65459668 2.72986903 0.05699624 0.14071315 0.52853161] 279.49865650537515\n",
      "[2.6706136  2.71345096 0.05893315 0.14077735 0.51326158] 279.5273378547443\n",
      "[2.68022059 2.70515451 0.05910695 0.14016758 0.50474983] 281.32129619019855\n",
      "[2.64823919 2.73658579 0.05633086 0.14503953 0.53132922] 279.8018404968293\n",
      "[2.65915903 2.71592365 0.05733713 0.13898109 0.52865984] 280.1213602934504\n",
      "[2.66812625 2.71228074 0.05863773 0.13617492 0.51101174] 281.8242469370731\n",
      "[2.65472706 2.72792173 0.05674959 0.14410388 0.52937317] 279.8581318407028\n",
      "[2.6574551  2.73429172 0.0571858  0.14598981 0.51813088] 280.48392537950315\n",
      "[2.65873305 2.72051567 0.05729929 0.14073327 0.5260276 ] 279.32546311701816\n",
      "[2.66348946 2.71933121 0.05799322 0.13951878 0.51607932] 279.6582867392565\n",
      "[2.67607745 2.70376532 0.05907689 0.13637483 0.50802331] 280.01548874336595\n",
      "[2.65519875 2.72838067 0.05701737 0.14287336 0.52550274] 279.6489565993694\n",
      "[2.65751089 2.72463968 0.0570242  0.14323741 0.52704258] 279.7158834271504\n",
      "[2.66199482 2.72065833 0.05775096 0.14044844 0.51882013] 279.6444244216063\n",
      "[2.66852002 2.71250129 0.05829348 0.13891287 0.51494611] 279.8966509214846\n",
      "[2.65852907 2.72441083 0.0573364  0.14188323 0.52286359] 279.38938513726794\n",
      "[2.66033766 2.72172463 0.05739406 0.14191171 0.5232461 ] 279.5191287375025\n",
      "[2.64760849 2.73224146 0.05559623 0.14203654 0.53279847] 279.45096713192527\n",
      "[2.65279278 2.72817453 0.05641619 0.14095212 0.52663489] 279.5858461027628\n",
      "[2.65845144 2.7233371  0.05714959 0.14167181 0.5240933 ] 279.54099895055384\n",
      "[2.65863106 2.72246325 0.05731785 0.14130825 0.52444559] 279.5768051999367\n",
      "[2.65317077 2.72637856 0.05644776 0.14138491 0.52941304] 279.5464976185729\n",
      "[2.66104592 2.71911329 0.05729838 0.14126331 0.52025441] 279.5828923663216\n",
      "[2.65666486 2.72519235 0.05714777 0.14072321 0.5272796 ] 279.6112307586262\n",
      "[2.65953535 2.72112015 0.05734668 0.14132249 0.52463685] 279.5753424218878\n",
      "[2.65978159 2.71864401 0.05713622 0.14168168 0.52263139] 279.54152874002233\n",
      "[2.65489481 2.72453537 0.05692074 0.14130893 0.53060738] 279.27533523958095\n",
      "[2.65181926 2.72724641 0.05673192 0.14133174 0.53578386] 279.578038944278\n",
      "[2.65581517 2.72201426 0.05674243 0.14126426 0.52888091] 279.5866274037642\n",
      "[2.65792709 2.722351   0.05717399 0.14129726 0.52555442] 279.5779387495937\n",
      "[2.65681393 2.72252552 0.05711002 0.1410211  0.52831749] 279.2997534835343\n",
      "[2.6573382  2.72158969 0.05702848 0.14149531 0.52661939] 279.5739390270134\n",
      "[2.65403279 2.72545697 0.05668425 0.14134692 0.53001021] 279.8942655442586\n",
      "[2.65721508 2.72282776 0.05713371 0.14131571 0.52762212] 279.9640666254027\n",
      "[2.65676293 2.72349931 0.05711929 0.14130859 0.52752649] 279.57677045966267\n",
      "[2.65472198 2.72421498 0.0568114  0.14127663 0.52961026] 279.90233880520674\n",
      "[2.65534526 2.72386818 0.05689198 0.1412864  0.52911323] 279.90119858963294\n",
      "[2.65659181 2.72317456 0.05705313 0.14130594 0.52811915] 279.96244754027816\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac6902240104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mOptimization\u001b[0m \u001b[0musing\u001b[0m \u001b[0mneadler\u001b[0m \u001b[0mmead\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0msimplex\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m minimum_nll = scipy.optimize.fmin(MLE_fmin, best_thetas, maxiter=10000, maxfun=10000, \n\u001b[0m\u001b[1;32m     59\u001b[0m                                   xtol=0.01, ftol=0.01)\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/glm/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(func, x0, args, xtol, ftol, maxiter, maxfun, full_output, disp, retall, callback, initial_simplex)\u001b[0m\n\u001b[1;32m    575\u001b[0m             'initial_simplex': initial_simplex}\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mretlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fun'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nfev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/glm/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, **unknown_options)\u001b[0m\n\u001b[1;32m    768\u001b[0m                     \u001b[0;31m# Perform an inside contraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                     \u001b[0mxcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxbar\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpsi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                     \u001b[0mfxcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfxcc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mfsim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/glm/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ac6902240104>\u001b[0m in \u001b[0;36mMLE_fmin\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;34m+=\u001b[0m \u001b[0mprobPerceptgivenLatentTones\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mLikelihoodLatentTonegivenHigh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitrue1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitrue2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitrue3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mLikelihoodPerceptgivenLow\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0;34m+=\u001b[0m \u001b[0mprobPerceptgivenLatentTones\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mLikelihoodLatentTonegivenLow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitrue1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitrue2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitrue3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprobHighgivenPercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLikelihoodPerceptgivenHigh\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob_low\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mLikelihoodPerceptgivenHigh\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprob_low\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mLikelihoodPerceptgivenLow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_low\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Means and p_back corresponding to the least negative log likelihood value\n",
    "\"\"\"\n",
    "idxs = np.where(neg_ll_array == np.amin(neg_ll_array)) \n",
    "best_thetas = np.array([guess_low_mean[idxs[0]], guess_high_mean[idxs[1]], guess_sigma[idxs[2]], \\\n",
    "                        guess_sensory_sigma[idxs[3]], guess_p_low[idxs[4]]])\n",
    "print(best_thetas, np.amin(neg_ll_array))\n",
    "\n",
    "# define mle function\n",
    "def MLE_fmin(params):\n",
    "    log_prior_low_mean, log_prior_high_mean, log_prior_sigma, sigma_sensory, prob_low = \\\n",
    "    params[0], params[1], params[2], params[3], params[4] # inputs are guesses at our parameters  \n",
    "    \n",
    "    LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow,_,_ = \\\n",
    "    posterior_array(log_freq_seq_array, n_tones=len(trial_tones[0]), p_low=prob_low,\n",
    "                    log_prior=[log_prior_low_mean,log_prior_high_mean,log_prior_sigma])\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    \n",
    "    for itrue1 in range(len(log_freq_seq_array)):\n",
    "        for itrue2 in range(len(log_freq_seq_array)):            \n",
    "            for itrue3 in range(len(log_freq_seq_array)):\n",
    "                probPerceptgivenLatentTones = Tones3dgrid([log_freq_seq_array[itrue1],\n",
    "                                                           log_freq_seq_array[itrue2],\n",
    "                                                           log_freq_seq_array[itrue3]],sigma=sigma_sensory)                                                           \n",
    "                LikelihoodPerceptgivenHigh \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                LikelihoodPerceptgivenLow \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*(prob_low))\n",
    "        \n",
    "    neg_ll = 0; \n",
    "    probability_high = np.zeros((len(trial_tones),1))\n",
    "    for i_trial in range(len(trial_tones)):\n",
    "        input_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_trial][0]),\n",
    "                                               np.log10(trial_tones[i_trial][1]),\n",
    "                                               np.log10(trial_tones[i_trial][2])]),sigma=sigma_sensory)\n",
    "        probability_high0 = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "        probability_high[i_trial] = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "            \n",
    "        if trial_behaviour[i_trial]:\n",
    "            if np.isnan(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isnan(np.log(1-probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(1-probability_high0 + 0.0000001)):\n",
    "                pdb.set_trace()\n",
    "            neg_ll += -np.log(probability_high0 + 0.0000001) # if high dist is chosen by observer\n",
    "        else:\n",
    "            neg_ll += -np.log(1 - probability_high0 + 0.0000001) # if low dist is chosen by observer\n",
    "    print(params,neg_ll)\n",
    "    return(neg_ll)\n",
    "\n",
    "\"\"\"\n",
    "Optimization using neadler mead method and a simplex algorithm\n",
    "\"\"\"\n",
    "minimum_nll = scipy.optimize.fmin(MLE_fmin, best_thetas, maxiter=10000, maxfun=10000, \n",
    "                                  xtol=0.01, ftol=0.01)\n",
    "\n",
    "print(minimum_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental task\n",
    "def task(freq_seq, lm, hm, s, n_trials = 10, n_tones = 3, p_low = 0.5, p_back = 0.3):\n",
    "    expt_log_freq_seq_array = np.arange(np.log10(freq_seq[0]), np.log10(freq_seq[-1]), \\\n",
    "                                   np.log10(1003/1000)*40)\n",
    "    print(expt_log_freq_seq_array)\n",
    "    log_freq_seq_mid = np.median(expt_log_freq_seq_array)\n",
    "    log_freq_low = [lm,s]#[log_freq_seq_mid - 0.15,0.1]  #low freq condition is gaussian \n",
    "    log_freq_high = [hm,s]#[log_freq_seq_mid + 0.15,0.1] #high freq condition is gaussian\n",
    "    trial_tones = []\n",
    "    dist_chosen = []\n",
    "    kind_of_tones = []\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        signal_rand = np.random.random()\n",
    "        low_dist = signal_rand < p_low #choosing true tone from either low or high condition\n",
    "        tones = []\n",
    "        tone_kind = []\n",
    "        for n_tone in range(n_tones):\n",
    "            signal_back = np.random.random()\n",
    "            background = signal_back < p_back #choosing background or true tone\n",
    "            if background:\n",
    "                nearest_log_tone = np.random.choice(expt_log_freq_seq_array)\n",
    "                #background freq is chosen from a uniform distribution\n",
    "                tone_kind.append(0)\n",
    "            else: \n",
    "                if low_dist:\n",
    "                    tone = min(max(np.random.randn()*log_freq_low[1] + log_freq_low[0],\\\n",
    "                                   expt_log_freq_seq_array[0]),expt_log_freq_seq_array[-1])                    \n",
    "                    tone_kind.append(1)\n",
    "                else:\n",
    "                    tone = min(max(np.random.randn()*log_freq_high[1] + log_freq_high[0],\\\n",
    "                                   expt_log_freq_seq_array[0]),expt_log_freq_seq_array[-1])\n",
    "                    tone_kind.append(2)\n",
    "                nearest_log_tone = expt_log_freq_seq_array[np.argmin(np.abs(expt_log_freq_seq_array - tone))]\n",
    "            nearest_tone = freq_seq[np.argmin(np.abs(freq_seq - 10**nearest_log_tone))]        \n",
    "            tones.append(nearest_tone)\n",
    "        trial_tones.append(tones)\n",
    "        dist_chosen.append(low_dist)\n",
    "        kind_of_tones.append(tone_kind)\n",
    "    return trial_tones, dist_chosen, kind_of_tones, log_freq_low, log_freq_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_behaviour(trial_tones, reps, n_tones, prob_low, log_prior_params, sigma_sensory):\n",
    "    \"\"\"\n",
    "    Trying two routes - 1. what if we have both sensory noise in that the perceived tones are from a gaussian \n",
    "    whose mean is the true tone and we have decision noise in that the at a particular perceived tone the observer \n",
    "    chooses high with probability p(H|T). So a trial is basically defined as [trial_tone, perceived_tone and \n",
    "    decision] \n",
    "    2. what if we only have sensory noise and the decision made is the best decision at a particular perceived \n",
    "    tone. \n",
    "\n",
    "    \"\"\"    \n",
    "\n",
    "    all_trial_tones = np.empty((len(trial_tones)*reps,n_tones))\n",
    "    all_trial_behaviour = np.empty((len(trial_tones)*reps,1))\n",
    "    prob_trial_behaviour = np.empty((len(trial_tones),1))\n",
    "    probability_sim_high = np.zeros((len(trial_tones),1))\n",
    "\n",
    "    LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow,_,_ = \\\n",
    "    posterior_array(log_freq_seq_array, n_tones=len(trial_tones[0]), p_low=prob_low,\\\n",
    "                    log_prior=log_prior_params)\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "\n",
    "    for itrue1 in range(len(log_freq_percept)):\n",
    "        for itrue2 in range(len(log_freq_percept)):\n",
    "            for itrue3 in range(len(log_freq_percept)):\n",
    "                probPerceptgivenLatentTones = Tones3dgrid([log_freq_percept[itrue1],\n",
    "                                                           log_freq_percept[itrue2],\n",
    "                                                           log_freq_percept[itrue3]],sigma=sigma_sensory)\n",
    "                LikelihoodPerceptgivenHigh \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                LikelihoodPerceptgivenLow \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*prob_low)\n",
    "\n",
    "    for i_stim in range(len(trial_tones)):\n",
    "        input_array = np.random.normal(loc=np.log10(trial_tones[i_stim]),scale=sigma_sensory,\n",
    "                                       size=(reps,1,n_tones)) \\\n",
    "        #pick tones from the gaussian with mean as log(true_tone) and sensory sigma 0.1    \n",
    "        for i_tperc in range(reps):\n",
    "            perc_tone_idxs = np.zeros((n_tones,1),dtype=int)\n",
    "            for i in range(n_tones):\n",
    "                perc_tone_idxs[i] = np.argmin(np.abs(log_freq_percept-input_array[i_tperc][0][i]))\n",
    "                # find relevant adjacent freq percepts   \n",
    "            posterior_perc_tone = probHighgivenPercept[perc_tone_idxs[0],perc_tone_idxs[1],perc_tone_idxs[2]]\n",
    "            # trial_behaviour = (np.random.random_sample() < np.squeeze(posterior_perc_tone)).astype(int)\n",
    "            # this encodes decision noise\n",
    "            trial_behaviour = np.squeeze(posterior_perc_tone) > 0.5\n",
    "            # this makes the same choice for one tone percept every time that tone is perceived   \n",
    "            all_trial_behaviour[i_stim*reps+i_tperc,:] = trial_behaviour\n",
    "        all_trial_tones[i_stim*reps:(i_stim+1)*reps,:] = trial_tones[i_stim]    \n",
    "        prob_trial_behaviour[i_stim] = np.mean(all_trial_behaviour[i_stim*reps:(i_stim+1)*reps])\n",
    "\n",
    "        gaussian_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_stim][0]),\n",
    "                                                   np.log10(trial_tones[i_stim][1]),\n",
    "                                                   np.log10(trial_tones[i_stim][2])]),sigma=sigma_sensory)         \n",
    "        probability_sim_high[i_stim] = np.sum(np.multiply(probHighgivenPercept>0.5, gaussian_array_mat))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Shuffling the tones and the behaviour to simluate an experiment\n",
    "\n",
    "    s = np.arange(all_trial_tones.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    all_trial_tones = all_trial_tones[s]\n",
    "    all_trial_behaviour = all_trial_behaviour[s]\n",
    "    \"\"\"\n",
    "    return all_trial_tones, probability_sim_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparing ideal subject strategies\n",
    "\"\"\"\n",
    "\n",
    "def plottingInfluenceFn(tones, behaviour):\n",
    "    unique_tones = np.unique(tones)\n",
    "\n",
    "    tone1_prob_behaviour = np.zeros((len(unique_tones)))\n",
    "    tone2_prob_behaviour = np.zeros((len(unique_tones)))\n",
    "    tone3_prob_behaviour = np.zeros((len(unique_tones)))\n",
    "\n",
    "    for i_tone in range(len(unique_tones)):\n",
    "        tone1_prob_behaviour[i_tone] = np.mean(behaviour[tones[:,0]==unique_tones[i_tone]])\n",
    "        tone2_prob_behaviour[i_tone] = np.mean(behaviour[tones[:,1]==unique_tones[i_tone]])\n",
    "        tone3_prob_behaviour[i_tone] = np.mean(behaviour[tones[:,2]==unique_tones[i_tone]])\n",
    "    mean_behaviour = (tone1_prob_behaviour+tone2_prob_behaviour+tone3_prob_behaviour)/3\n",
    "    return unique_tones, mean_behaviour    \n",
    "    \n",
    "unique_tones_played, subjectBehaviour = plottingInfluenceFn(trial_tones, trial_behaviour)    \n",
    "influence, = plt.plot(np.log10(unique_tones_played), subjectBehaviour, 'k', label = 'Average Influence')\n",
    "\n",
    "moreTrainingTrials, _,_,_,_ = task(freq_seq = expt_tones, \n",
    "                                    n_trials = 6000, n_tones = 3, \n",
    "                                    p_back=0.3, p_low=0.3,\n",
    "                                    lm=2.55,hm=2.85,s=0.1)\n",
    "\n",
    "all_trial_tones, probability_sim_high = generate_behaviour(moreTrainingTrials, reps=1, n_tones=3, \n",
    "                                                          prob_low=0.64,\n",
    "                                                          log_prior_params=[2.55,2.79,0.05], \n",
    "                                                          sigma_sensory=0.26)\n",
    "\n",
    "unique_tones_played, subjectBehaviourBasedOnModel = plottingInfluenceFn(all_trial_tones, probability_sim_high) \n",
    "\n",
    "mnll_influence, = plt.plot(np.log10(unique_tones_played), subjectBehaviourBasedOnModel, \n",
    "                      'r--', label = 'p(B_H|T) given fmin parameters')\n",
    "\n",
    "\n",
    "plt.xlim([1.9,3.6])\n",
    "plt.ylim([-0.2,1.1])\n",
    "plt.xticks(ticks=np.arange(1.9,3.6,0.4), labels=np.around(10**np.arange(1.9,3.6,0.4),2),fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('log10(Tones)',fontsize=15)\n",
    "plt.ylabel('p(B_H|T)',fontsize=15)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/FromProlific/rawDataAnalysis/experimenter=e12e_cleaner_modelfit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What does the underlying posterior look like?\n",
    "\"\"\"\n",
    "\n",
    "def posteriorAgainstPercept(expt_Params):\n",
    "    [mle_LikelihoodLatentTonegivenHigh,\n",
    "    mle_LikelihoodLatentTonegivenLow,_,mle_posterior] = posterior_array(freq_input=log_freq_percept,\n",
    "                                                                        n_tones=3,\n",
    "                                                                        p_low=expt_Params[4],\n",
    "                                                                        log_prior=expt_Params[:3]) \n",
    "    \n",
    "    \n",
    "    mle_LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),\n",
    "                                               len(log_freq_percept),len(log_freq_percept)))\n",
    "    mle_LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),\n",
    "                                              len(log_freq_percept),len(log_freq_percept)))\n",
    "\n",
    "    for itrue1 in range(len(log_freq_percept)):\n",
    "        for itrue2 in range(len(log_freq_percept)):\n",
    "            for itrue3 in range(len(log_freq_percept)):\n",
    "                mle_probPerceptgivenLatentTones = Tones3dgrid([log_freq_percept[itrue1],\n",
    "                                                               log_freq_percept[itrue2],\n",
    "                                                               log_freq_percept[itrue3]],\n",
    "                                                               sigma=expt_Params[3])\n",
    "                mle_LikelihoodPerceptgivenHigh \\\n",
    "                += mle_probPerceptgivenLatentTones * mle_LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                mle_LikelihoodPerceptgivenLow \\\n",
    "                += mle_probPerceptgivenLatentTones * mle_LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    mle_probHighgivenPercept = mle_LikelihoodPerceptgivenHigh*(1-expt_Params[4])/\\\n",
    "    (mle_LikelihoodPerceptgivenHigh*(1-expt_Params[4]) + mle_LikelihoodPerceptgivenLow*expt_Params[4])\n",
    "    return mle_probHighgivenPercept\n",
    "\n",
    "minMLE_probHighgivenPercept = posteriorAgainstPercept([2.51,2.85,0.052,0.16,0.57])\n",
    "\n",
    "tone1_prob_behaviour = np.zeros((len(log_freq_percept)))\n",
    "tone2_prob_behaviour = np.zeros((len(log_freq_percept)))\n",
    "tone3_prob_behaviour = np.zeros((len(log_freq_percept)))\n",
    "\n",
    "for i_tone in range(len(log_freq_percept)):\n",
    "    tone1_prob_behaviour[i_tone] = np.mean(minMLE_probHighgivenPercept[i_tone,:,:])\n",
    "    tone2_prob_behaviour[i_tone] = np.mean(minMLE_probHighgivenPercept[:,i_tone,:])\n",
    "    tone3_prob_behaviour[i_tone] = np.mean(minMLE_probHighgivenPercept[:,:,i_tone])\n",
    "\n",
    "posteriorProbabilities = (tone1_prob_behaviour+tone2_prob_behaviour+tone3_prob_behaviour)/3\n",
    "posteriorProbabilities = posteriorProbabilities - np.mean(posteriorProbabilities)\n",
    "plt.plot(log_freq_percept, posteriorProbabilities, \n",
    "         'k--')\n",
    "plt.xlabel('Tones',fontsize=15)\n",
    "plt.ylabel('p(B_H|T)',fontsize=15)\n",
    "plt.xticks(ticks=np.arange(0.6,4.7,1), labels=np.around(10**np.arange(0.6,4.7,1),2),fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()  \n",
    "print(\"Norm of distractor weights compared to norm of all weights no context\",\n",
    "      (sum(np.abs(posteriorProbabilities[:17]))+\n",
    "       sum(np.abs(posteriorProbabilities[-16:])))/sum(np.abs(posteriorProbabilities)))\n",
    "pd.DataFrame(posteriorProbabilities).to_csv(\"figures/FromProlific/rawDataAnalysis/e12e_noContext_posteriorProbabilities.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

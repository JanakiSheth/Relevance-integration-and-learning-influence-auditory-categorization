{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import scipy\n",
    "from scipy.optimize import minimize, fmin\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['tahoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Obtaining data from a given expt\n",
    "\"\"\"\n",
    "csv_test = pd.read_csv('../auditory_categorization_noContext/important_things_not_included_in_assets/allTrials_noBias.csv')\n",
    "csv_data = pd.read_csv('subjectDataForPlots/noContextData/607da39df127ab6004a8cd10_categorization_task_2021-10-15_22h42.14.568.csv');\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tones = 3\n",
    "n_trials = csv_data.shape[0]-47\n",
    "\n",
    "\"\"\"\n",
    "Get tones and values of keys pressed\n",
    "\"\"\"\n",
    "test_columns = list(csv_test.columns)\n",
    "test_tones_name = test_columns.index('Name')\n",
    "test_tones_col_idx = test_columns.index('Tones')\n",
    "df_names = (csv_test.iloc[0:600,test_tones_name]).values\n",
    "df_tones = (csv_test.iloc[0:600,test_tones_col_idx]).values\n",
    "\n",
    "tones_array_orig = np.zeros((n_trials,n_tones))\n",
    "tones_array_idxs_keep = []\n",
    "\n",
    "for i_wav in range(603):\n",
    "    if isinstance(csv_data['Name'][i_wav+46],str):\n",
    "        tones_array_orig[i_wav,:] = np.array(df_tones[np.where(csv_data['Name'][i_wav+46]\n",
    "                                                               ==df_names)[0]][0][1:-1].split(',')).astype(float)  \n",
    "        tones_array_idxs_keep += [i_wav]\n",
    "\n",
    "        \n",
    "df_tones = np.copy(tones_array_orig[tones_array_idxs_keep,:])\n",
    "df_corrans = np.copy(csv_data['corrAns'][46:csv_data.shape[0]])[tones_array_idxs_keep]\n",
    "df_keys = np.copy(csv_data['test_resp.keys'][46:csv_data.shape[0]])[tones_array_idxs_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find no response cases in the expt\n",
    "\"\"\"\n",
    "no_response = np.intersect1d(np.where(df_keys!='h')[0],np.where(df_keys!='l')[0])\n",
    "print(\"Did not respond to: \",no_response)\n",
    "\n",
    "\"\"\"\n",
    "Convert keys ['l','h'] to [0,1] and calculate accuracies\n",
    "\"\"\"\n",
    "corrans_num_orig = np.zeros_like(df_corrans)\n",
    "corrans_num_orig[df_corrans == 'h'] = 1\n",
    "\n",
    "keys_num_orig = np.zeros_like(df_keys)\n",
    "keys_num_orig[df_keys == 'h'] = 1\n",
    "\n",
    "corrans_num = corrans_num_orig[:600]\n",
    "keys_num = keys_num_orig[:600]\n",
    "tones_array = df_tones[:600]\n",
    "print(\"Got correct: \", np.sum(keys_num==corrans_num)/len(tones_array))\n",
    "print(\"Got high correct: \", np.sum((keys_num)*(corrans_num))/np.sum(corrans_num))\n",
    "print(\"Got low correct: \", np.sum((1-keys_num)*(1-corrans_num))/np.sum(1-corrans_num))\n",
    "\n",
    "\"\"\"\n",
    "Defining expt variable\n",
    "\"\"\"\n",
    "\n",
    "trial_tones = np.repeat(tones_array,1,axis = 0)\n",
    "trial_behaviour = np.reshape(keys_num,np.prod(keys_num.shape)) \n",
    "#this has been changed to check how values change with observer responses\n",
    "\n",
    "expt_tones = np.arange(90,3000,1) #array of possible true tones\n",
    "log_freq_seq_array = np.arange(0.6,4.7,0.1)\n",
    "log_freq_percept = np.arange(0.6,4.7,0.1) # array of possible perceptual tones\n",
    "\n",
    "idxs_with_response = np.delete(np.arange(len(trial_tones)),no_response)\n",
    "trial_tones = trial_tones[idxs_with_response,:]\n",
    "trial_behaviour = trial_behaviour[idxs_with_response]\n",
    "trial_corrans = corrans_num[idxs_with_response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mean, sigma):\n",
    "    return np.exp(-(x-mean)**2/(2*sigma**2))\n",
    "\n",
    "def Tones3dgrid(latentTones, sigma):    \n",
    "    \n",
    "    input_array_0 = np.expand_dims(gaussian(log_freq_percept, latentTones[0], sigma), axis = 1)\n",
    "    input_array_1 = np.expand_dims(gaussian(log_freq_percept, latentTones[1], sigma), axis = 1)\n",
    "    input_array_2 = np.expand_dims(gaussian(log_freq_percept, latentTones[2], sigma), axis = 1)\n",
    "    s0 = 1/np.sum(input_array_0); \n",
    "    s1 = 1/np.sum(input_array_1); \n",
    "    s2 = 1/np.sum(input_array_2);\n",
    "    input_array_0 *= s0; \n",
    "    input_array_1 *= s1; \n",
    "    input_array_2 *= s2; \n",
    "    \n",
    "    input_array_mat = np.expand_dims(input_array_0@input_array_1.T,axis=2)@(input_array_2.T) #p(T1,T2..|H)   \n",
    "                                     \n",
    "    return input_array_mat\n",
    "\n",
    "\n",
    "def posterior_array(freq_input, n_tones, p_back, log_prior):\n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "    freq_input - range of all possible frequencies (percepts?)\n",
    "    p_back - prob of background\n",
    "    p_low - prob of low condition\n",
    "    log_prior - list of prior parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    log_prior_low_mean = log_prior[0]; log_prior_low_sigma = log_prior[2];\n",
    "    log_prior_high_mean = log_prior[1]; log_prior_high_sigma = log_prior[2];\n",
    "    likelihood_onetone_low = gaussian(x=freq_input, mean=log_prior_low_mean, sigma=log_prior_low_sigma)\n",
    "    likelihood_onetone_high = gaussian(x=freq_input, mean=log_prior_high_mean, sigma=log_prior_high_sigma)\n",
    "    likelihood_onetone_mixed_high = p_back*(1/len(freq_input)) + (1-p_back)*likelihood_onetone_high \\\n",
    "    #mixture model with p(T|B) = 1/no. of possible freqs\n",
    "    likelihood_onetone_mixed_high /= likelihood_onetone_mixed_high.sum() #normalizing\n",
    "    likelihood_onetone_mixed_high = np.expand_dims(likelihood_onetone_mixed_high, axis = 1)\n",
    "    likelihood_onetone_mixed_low = p_back*(1/len(freq_input)) + (1-p_back)*likelihood_onetone_low \\\n",
    "    #mixture model with p(T|B) = 1/no. of possible freqs\n",
    "    likelihood_onetone_mixed_low /= likelihood_onetone_mixed_low.sum() #normalizing\n",
    "    likelihood_onetone_mixed_low = np.expand_dims(likelihood_onetone_mixed_low, axis = 1)\n",
    "        \n",
    "    if n_tones == 3:\n",
    "        likelihood_alltones_low = (np.expand_dims(likelihood_onetone_mixed_low@np.transpose\n",
    "                                                 (likelihood_onetone_mixed_low),axis=2)\n",
    "                                   @np.transpose(likelihood_onetone_mixed_low))\n",
    "        #p(T1,T2..|L) \n",
    "        likelihood_alltones_high = (np.expand_dims(likelihood_onetone_mixed_high@np.transpose\n",
    "                                                 (likelihood_onetone_mixed_high),axis=2)\n",
    "                                    @np.transpose(likelihood_onetone_mixed_high))\n",
    "        #p(T1,T2..|H) \n",
    "    elif n_tones == 1:\n",
    "        likelihood_alltones_low = likelihood_onetone_mixed_low\n",
    "        likelihood_alltones_high = likelihood_onetone_mixed_high\n",
    "\n",
    "    return [likelihood_onetone_mixed_high, likelihood_onetone_mixed_low, \n",
    "            likelihood_alltones_high, likelihood_alltones_low]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mle function\n",
    "def MLE(params):\n",
    "    log_prior_low_mean, log_prior_high_mean, log_prior_sigma, sigma_sensory, prob_back, prob_low = \\\n",
    "    params[0], params[1], params[2], params[3], params[4], params[5] # inputs are guesses at our parameters  \n",
    "    \n",
    "    [_,_,LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow] = \\\n",
    "    posterior_array(log_freq_seq_array, n_tones=len(trial_tones[0]), \n",
    "                    p_back=prob_back, log_prior=log_prior_params)\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    \n",
    "    for itrue1 in range(len(log_freq_seq_array)):\n",
    "        for itrue2 in range(len(log_freq_seq_array)):            \n",
    "            for itrue3 in range(len(log_freq_seq_array)):\n",
    "                probPerceptgivenLatentTones = Tones3dgrid([log_freq_seq_array[itrue1],\\\n",
    "                                                           log_freq_seq_array[itrue2],\\\n",
    "                                                           log_freq_seq_array[itrue3]],sigma=sigma_sensory)                                                           \n",
    "                LikelihoodPerceptgivenHigh \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                LikelihoodPerceptgivenLow \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*(prob_low))\n",
    "        \n",
    "    neg_ll = 0; \n",
    "    probability_high = np.zeros((len(trial_tones),1))\n",
    "    for i_trial in range(len(trial_tones)):\n",
    "        input_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_trial][0]),\\\n",
    "                                               np.log10(trial_tones[i_trial][1]),\n",
    "                                               np.log10(trial_tones[i_trial][2])]),sigma=sigma_sensory)\n",
    "        probability_high0 = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "        probability_high[i_trial] = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "            \n",
    "        if trial_behaviour[i_trial]:\n",
    "            if np.isnan(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isnan(np.log(1-probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(1-probability_high0 + 0.0000001)):\n",
    "                pdb.set_trace()\n",
    "            neg_ll += -np.log(probability_high0 + 0.0000001) # if high dist is chosen by observer\n",
    "        else:\n",
    "            neg_ll += -np.log(1 - probability_high0 + 0.0000001) # if low dist is chosen by observer\n",
    "    return(neg_ll, probability_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental task\n",
    "def task(freq_seq, lm, hm, s, n_trials = 10, n_tones = 3, p_low = 0.5, p_back = 0.3):\n",
    "    expt_log_freq_seq_array = np.arange(np.log10(freq_seq[0]), np.log10(freq_seq[-1]), \\\n",
    "                                   np.log10(1003/1000)*40)\n",
    "    print(expt_log_freq_seq_array)\n",
    "    log_freq_seq_mid = np.median(expt_log_freq_seq_array)\n",
    "    log_freq_low = [lm,s]#[log_freq_seq_mid - 0.15,0.1]  #low freq condition is gaussian \n",
    "    log_freq_high = [hm,s]#[log_freq_seq_mid + 0.15,0.1] #high freq condition is gaussian\n",
    "    trial_tones = []\n",
    "    dist_chosen = []\n",
    "    kind_of_tones = []\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        signal_rand = np.random.random()\n",
    "        low_dist = signal_rand < p_low #choosing true tone from either low or high condition\n",
    "        tones = []\n",
    "        tone_kind = []\n",
    "        for n_tone in range(n_tones):\n",
    "            signal_back = np.random.random()\n",
    "            background = signal_back < p_back #choosing background or true tone\n",
    "            if background:\n",
    "                nearest_log_tone = np.random.choice(expt_log_freq_seq_array)\n",
    "                #background freq is chosen from a uniform distribution\n",
    "                tone_kind.append(0)\n",
    "            else: \n",
    "                if low_dist:\n",
    "                    tone = min(max(np.random.randn()*log_freq_low[1] + log_freq_low[0],\\\n",
    "                                   expt_log_freq_seq_array[0]),expt_log_freq_seq_array[-1])                    \n",
    "                    tone_kind.append(1)\n",
    "                else:\n",
    "                    tone = min(max(np.random.randn()*log_freq_high[1] + log_freq_high[0],\\\n",
    "                                   expt_log_freq_seq_array[0]),expt_log_freq_seq_array[-1])\n",
    "                    tone_kind.append(2)\n",
    "                nearest_log_tone = expt_log_freq_seq_array[np.argmin(np.abs(expt_log_freq_seq_array - tone))]\n",
    "            nearest_tone = freq_seq[np.argmin(np.abs(freq_seq - 10**nearest_log_tone))]        \n",
    "            tones.append(nearest_tone)\n",
    "        trial_tones.append(tones)\n",
    "        dist_chosen.append(low_dist)\n",
    "        kind_of_tones.append(tone_kind)\n",
    "    return trial_tones, dist_chosen, kind_of_tones, log_freq_low, log_freq_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_behaviour(trial_tones, reps, n_tones, prob_back, prob_low, log_prior_params, sigma_sensory):\n",
    "    \"\"\"\n",
    "    Trying two routes - 1. what if we have both sensory noise in that the perceived tones are from a gaussian \n",
    "    whose mean is the true tone and we have decision noise in that the at a particular perceived tone the observer \n",
    "    chooses high with probability p(H|T). So a trial is basically defined as [trial_tone, perceived_tone and \n",
    "    decision] \n",
    "    2. what if we only have sensory noise and the decision made is the best decision at a particular perceived \n",
    "    tone. \n",
    "\n",
    "    \"\"\"    \n",
    "\n",
    "    all_trial_tones = np.empty((len(trial_tones)*reps,n_tones))\n",
    "    all_trial_behaviour = np.empty((len(trial_tones)*reps,1))\n",
    "    prob_trial_behaviour = np.empty((len(trial_tones),1))\n",
    "    probability_sim_high = np.zeros((len(trial_tones),1))\n",
    "\n",
    "    [_,_,LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow] = \\\n",
    "    posterior_array(log_freq_seq_array, n_tones=len(trial_tones[0]), \n",
    "                    p_back=prob_back, log_prior=log_prior_params)\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "\n",
    "    for itrue1 in range(len(log_freq_percept)):\n",
    "        for itrue2 in range(len(log_freq_percept)):\n",
    "            for itrue3 in range(len(log_freq_percept)):\n",
    "                probPerceptgivenLatentTones = Tones3dgrid([log_freq_percept[itrue1],\n",
    "                                                           log_freq_percept[itrue2],\n",
    "                                                           log_freq_percept[itrue3]],sigma=sigma_sensory)\n",
    "                LikelihoodPerceptgivenHigh \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                LikelihoodPerceptgivenLow \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*prob_low)\n",
    "\n",
    "    for i_stim in range(len(trial_tones)):\n",
    "        input_array = np.random.normal(loc=np.log10(trial_tones[i_stim]),scale=sigma_sensory,\n",
    "                                       size=(reps,1,n_tones)) \\\n",
    "        #pick tones from the gaussian with mean as log(true_tone) and sensory sigma 0.1    \n",
    "        for i_tperc in range(reps):\n",
    "            perc_tone_idxs = np.zeros((n_tones,1),dtype=int)\n",
    "            for i in range(n_tones):\n",
    "                perc_tone_idxs[i] = np.argmin(np.abs(log_freq_percept-input_array[i_tperc][0][i]))\n",
    "                # find relevant adjacent freq percepts   \n",
    "            posterior_perc_tone = probHighgivenPercept[perc_tone_idxs[0],perc_tone_idxs[1],perc_tone_idxs[2]]\n",
    "            # trial_behaviour = (np.random.random_sample() < np.squeeze(posterior_perc_tone)).astype(int)\n",
    "            # this encodes decision noise\n",
    "            trial_behaviour = np.squeeze(posterior_perc_tone) > 0.5\n",
    "            # this makes the same choice for one tone percept every time that tone is perceived   \n",
    "            all_trial_behaviour[i_stim*reps+i_tperc,:] = trial_behaviour\n",
    "        all_trial_tones[i_stim*reps:(i_stim+1)*reps,:] = trial_tones[i_stim]    \n",
    "        prob_trial_behaviour[i_stim] = np.mean(all_trial_behaviour[i_stim*reps:(i_stim+1)*reps])\n",
    "\n",
    "        gaussian_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_stim][0]),\n",
    "                                                   np.log10(trial_tones[i_stim][1]),\n",
    "                                                   np.log10(trial_tones[i_stim][2])]),sigma=sigma_sensory)         \n",
    "        probability_sim_high[i_stim] = np.sum(np.multiply(probHighgivenPercept>0.5, gaussian_array_mat))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Shuffling the tones and the behaviour to simluate an experiment\n",
    "\n",
    "    s = np.arange(all_trial_tones.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    all_trial_tones = all_trial_tones[s]\n",
    "    all_trial_behaviour = all_trial_behaviour[s]\n",
    "    \"\"\"\n",
    "    return all_trial_tones, probability_sim_high\n",
    "\n",
    "def generate_behaviourRandomChoice(params, trial_tones):\n",
    "    sigma_sensory, prob_low = params[0], params[1] # inputs are guesses at our parameters  \n",
    "    \n",
    "    prob_trial_behaviour = np.zeros((len(trial_tones),1))\n",
    "    for i_trial in range(len(trial_tones)):\n",
    "        gaussian_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_trial][0]),\n",
    "                                                   np.log10(trial_tones[i_trial][1]),\n",
    "                                                   np.log10(trial_tones[i_trial][2])]),sigma=sigma_sensory)\n",
    "        prob_trial_behaviour[i_trial] = np.sum(np.multiply((1-prob_low), gaussian_array_mat))\n",
    "            \n",
    "    return(prob_trial_behaviour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting cleaner fits from model by generating 1000 tone trials and corresponding behavior\n",
    "\"\"\"\n",
    "\n",
    "def plottingInfluenceFn(tones, behaviour):\n",
    "    unique_tones = np.unique(tones)\n",
    "\n",
    "    tone1_prob_behaviour = np.zeros((len(unique_tones),1))\n",
    "    tone2_prob_behaviour = np.zeros((len(unique_tones),1))\n",
    "    tone3_prob_behaviour = np.zeros((len(unique_tones),1))\n",
    "\n",
    "    for i_tone in range(len(unique_tones)):\n",
    "        tone1_prob_behaviour[i_tone] = np.mean(behaviour[tones[:,0]==unique_tones[i_tone]])\n",
    "        tone2_prob_behaviour[i_tone] = np.mean(behaviour[tones[:,1]==unique_tones[i_tone]])\n",
    "        tone3_prob_behaviour[i_tone] = np.mean(behaviour[tones[:,2]==unique_tones[i_tone]])\n",
    "    behaviour = np.concatenate((tone1_prob_behaviour,tone2_prob_behaviour,tone3_prob_behaviour),axis=1)\n",
    "    return unique_tones, behaviour\n",
    "\n",
    "def localVsGlobalEffect(tones,corrAns,behaviour):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prev trial is overrepresented\n",
    "    \"\"\"\n",
    "    trialsIdxs = np.arange(len(corrAns)-1)\n",
    "    lowCategoryIdx = trialsIdxs[corrAns[:-1]==0]\n",
    "    trialsSucceedingLowCategory = tones[lowCategoryIdx+1,:]\n",
    "    behaviourSucceedingLowCategory = behaviour[lowCategoryIdx+1]\n",
    "    corransSucceedingLowCategory = corrAns[lowCategoryIdx+1]\n",
    "\n",
    "    [unique_tonesPlayed, \n",
    "    subjectBehaviourPrevTrialLowCategory] = plottingInfluenceFn(trialsSucceedingLowCategory,\n",
    "                                                               behaviourSucceedingLowCategory)\n",
    "    \n",
    "    \"\"\"\n",
    "    Prev trial is underrepresented\n",
    "    \"\"\"\n",
    "    highCategoryIdx = trialsIdxs[corrAns[:-1]==1]\n",
    "    trialsSucceedingHighCategory = tones[highCategoryIdx+1,:]\n",
    "    behaviourSucceedingHighCategory = behaviour[highCategoryIdx+1]\n",
    "    corransSucceedingHighCategory = corrAns[highCategoryIdx+1]\n",
    "    \n",
    "    [unique_tonesPlayed, \n",
    "    subjectBehaviourPrevTrialHighCategory] = plottingInfluenceFn(trialsSucceedingHighCategory,\n",
    "                                                                 behaviourSucceedingHighCategory)\n",
    "    return unique_tonesPlayed, subjectBehaviourPrevTrialLowCategory, subjectBehaviourPrevTrialHighCategory\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Value of constraint to restrict the range of parameter fits for short term context\n",
    "\"\"\"\n",
    "\n",
    "[unique_tones, meanBehaviourAfterLowTrial, \n",
    "meanBehaviourAfterHighTrial] = localVsGlobalEffect(tones=trial_tones, \n",
    "                                                    behaviour=trial_behaviour, \n",
    "                                                    corrAns=trial_corrans)\n",
    "plt.errorbar(np.log10(unique_tones), np.mean(meanBehaviourAfterLowTrial,axis=1),\n",
    "             yerr=np.std(meanBehaviourAfterLowTrial,axis=1)/np.sqrt(3), \n",
    "             color='orange',linestyle='--',linewidth=2)\n",
    "plt.errorbar(np.log10(unique_tones), np.mean(meanBehaviourAfterHighTrial,axis=1),\n",
    "             yerr=np.std(meanBehaviourAfterHighTrial,axis=1)/np.sqrt(3), \n",
    "             color='orange',linestyle='dotted',linewidth=2)\n",
    "\n",
    "constraint = np.nanmean(meanBehaviourAfterLowTrial,axis=1) - np.nanmean(meanBehaviourAfterHighTrial,axis=1)\n",
    "\n",
    "print(np.abs(np.mean(constraint)/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fitting the different models to the data\n",
    "\"\"\"\n",
    "unique_tones_played, subjectBehaviour = plottingInfluenceFn(trial_tones, trial_behaviour) \n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "plt.errorbar(np.log10(unique_tones_played), np.mean(subjectBehaviour,axis=1),\n",
    "             yerr=np.std(subjectBehaviour,axis=1)/np.sqrt(3),color='k',linewidth=2)\n",
    "\n",
    "moreTrainingTrials, _,_,_,_ = task(freq_seq = expt_tones, \n",
    "                                    n_trials = 8000, n_tones = 3, \n",
    "                                    p_back=0.3, p_low=0.5,\n",
    "                                    lm=2.55,hm=2.85,s=0.1)\n",
    "\n",
    "all_trial_tones, simulated_behaviour = generate_behaviour(moreTrainingTrials, reps=1, n_tones=3, \n",
    "                                                          sigma_sensory=0.52,\n",
    "                                                          prob_low = 0.43,\n",
    "                                                          prob_back = 0.36, \n",
    "                                                          log_prior_params=[2.55,2.85,0.1])\n",
    "\n",
    "unique_tones_played, allTonePositionssubjectBehaviourModelled = plottingInfluenceFn(all_trial_tones, \n",
    "                                                                                    simulated_behaviour) \n",
    "\n",
    "plt.errorbar(np.log10(unique_tones_played), np.mean(allTonePositionssubjectBehaviourModelled,axis=1),\n",
    "             yerr=np.std(allTonePositionssubjectBehaviourModelled,axis=1)/np.sqrt(3), \n",
    "             color='red',linestyle='--',linewidth=2)\n",
    "\n",
    "all_trial_tones, simulated_behaviour = generate_behaviour(moreTrainingTrials, reps=1, n_tones=3, \n",
    "                                                          sigma_sensory = 0.52,\n",
    "                                                          prob_back = 0,\n",
    "                                                          prob_low = 0.43,\n",
    "                                                          log_prior_params = [2.55,2.85,0.1])\n",
    "\n",
    "unique_tones_played, allTonePositionsSubjectBehaviourModelled = plottingInfluenceFn(all_trial_tones, \n",
    "                                                                                    simulated_behaviour)\n",
    "plt.errorbar(np.log10(unique_tones_played), \n",
    "             np.mean(allTonePositionsSubjectBehaviourModelled,axis=1),\n",
    "             yerr = np.std(allTonePositionsSubjectBehaviourModelled,axis=1)/np.sqrt(3),\n",
    "             color='lightsalmon',linestyle='dotted',linewidth=2)\n",
    "\n",
    "simulated_behaviour = generate_behaviourRandomChoice([0.52,0.43],\n",
    "                                                    moreTrainingTrials)\n",
    "\n",
    "unique_tones_played, allTonePositionsSubjectBehaviourModelled = plottingInfluenceFn(all_trial_tones, \n",
    "                                                                                    simulated_behaviour)\n",
    "plt.errorbar(np.log10(unique_tones_played), \n",
    "             np.mean(allTonePositionsSubjectBehaviourModelled,axis=1),\n",
    "             yerr = np.std(allTonePositionsSubjectBehaviourModelled,axis=1)/np.sqrt(3),\n",
    "             color='teal',linestyle='dashdot',linewidth=2)\n",
    "\n",
    "ax.set_xlim([1.9,3.6])\n",
    "ax.set_ylim([-0.02,1.1])\n",
    "ax.set_xticks(ticks=np.log10([100,1000,3000]))\n",
    "ax.set_xticklabels([100,1000,3000])\n",
    "ax.tick_params(axis='both',labelsize=30,length=6,width=2)\n",
    "ax.set_xlabel('Frequency (Hz)',fontsize=32)\n",
    "ax.set_ylabel(r'p($\\rm{\\widehat{High}}$)',fontsize=32)\n",
    "ax.set_yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "ax.set_yticklabels([0,0.2,0.4,0.6,0.8,1.0])\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/FromProlific/illustrations/experimenter=cd10_cleaner_modelfit.pdf',\n",
    "           bbox_inches='tight',transparent=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What does the underlying posterior look like?\n",
    "\"\"\"\n",
    "\n",
    "def posteriorAgainstPercept(expt_Params):\n",
    "    [_,_,mle_LikelihoodLatentTonegivenHigh,\n",
    "    mle_LikelihoodLatentTonegivenLow] = posterior_array(freq_input=log_freq_percept,\n",
    "                                                                        n_tones=3,p_back=expt_Params[4],\n",
    "                                                                        log_prior=expt_Params[:3]) \n",
    "    \n",
    "    \n",
    "    mle_LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),\n",
    "                                               len(log_freq_percept),len(log_freq_percept)))\n",
    "    mle_LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),\n",
    "                                              len(log_freq_percept),len(log_freq_percept)))\n",
    "\n",
    "    for itrue1 in range(len(log_freq_percept)):\n",
    "        for itrue2 in range(len(log_freq_percept)):\n",
    "            for itrue3 in range(len(log_freq_percept)):\n",
    "                mle_probPerceptgivenLatentTones = Tones3dgrid([log_freq_percept[itrue1],\n",
    "                                                               log_freq_percept[itrue2],\n",
    "                                                               log_freq_percept[itrue3]],\n",
    "                                                               sigma=expt_Params[3])\n",
    "                mle_LikelihoodPerceptgivenHigh \\\n",
    "                += mle_probPerceptgivenLatentTones * mle_LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                mle_LikelihoodPerceptgivenLow \\\n",
    "                += mle_probPerceptgivenLatentTones * mle_LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    mle_probHighgivenPercept = mle_LikelihoodPerceptgivenHigh*(1-expt_Params[5])/\\\n",
    "    (mle_LikelihoodPerceptgivenHigh*(1-expt_Params[5]) + mle_LikelihoodPerceptgivenLow*expt_Params[5])\n",
    "    return mle_probHighgivenPercept\n",
    "\n",
    "minMLE_probHighgivenPercept = posteriorAgainstPercept([2.55,2.85,0.1,0.52,0.36,0.43])\n",
    "\n",
    "tone1_prob_behaviour = np.zeros((len(log_freq_percept)))\n",
    "tone2_prob_behaviour = np.zeros((len(log_freq_percept)))\n",
    "tone3_prob_behaviour = np.zeros((len(log_freq_percept)))\n",
    "\n",
    "for i_tone in range(len(log_freq_percept)):\n",
    "    tone1_prob_behaviour[i_tone] = np.mean(minMLE_probHighgivenPercept[i_tone,:,:])\n",
    "    tone2_prob_behaviour[i_tone] = np.mean(minMLE_probHighgivenPercept[:,i_tone,:])\n",
    "    tone3_prob_behaviour[i_tone] = np.mean(minMLE_probHighgivenPercept[:,:,i_tone])\n",
    "\n",
    "posteriorProbabilities = (tone1_prob_behaviour+tone2_prob_behaviour+tone3_prob_behaviour)/3\n",
    "posteriorProbabilities = posteriorProbabilities - posteriorProbabilities[0]\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.errorbar(log_freq_percept, posteriorProbabilities,\n",
    "            yerr=np.std([tone1_prob_behaviour,tone2_prob_behaviour,tone3_prob_behaviour],axis=0)/np.sqrt(3),\n",
    "            color='black', ls='dotted',Linewidth=4)\n",
    "ax.set_xlabel('Modeled sensory evidence',fontsize=34)\n",
    "ax.set_ylabel(r'p($\\rm{\\widehat{High}}$)',fontsize=34)\n",
    "ax.set_xticks(ticks=np.arange(1,4.7,1))\n",
    "ax.set_xticklabels(np.ceil(10**np.arange(1,4.7,1)).astype(int))\n",
    "ax.set_yticks(ticks=[-0.2,0,0.2])\n",
    "ax.tick_params(axis='both',labelsize=32,length=6,width=2)\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()  \n",
    "print(\"Norm of distractor weights compared to norm of all weights no context\",\n",
    "      (sum(np.abs(posteriorProbabilities[:17]))+\n",
    "       sum(np.abs(posteriorProbabilities[-15:])))/sum(np.abs(posteriorProbabilities)))\n",
    "plt.savefig('figures/FromProlific/illustrations/experimenter=cd10_posteriorUsingPercepts.pdf',\n",
    "           bbox_inches='tight',transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "New optimization algorithm: uses scipy.optimize.fmin. \n",
    "Crude grid initially and then find minimum using the function.\n",
    "\"\"\"\n",
    "guess_low_mean = np.arange(2.1,2.71,0.15); guess_high_mean = np.arange(2.7,3.31,0.15); \n",
    "guess_sigma = np.arange(0.05,1,0.2); guess_sensory_sigma = np.array([0.14]);\n",
    "guess_p_back = np.array([0]); guess_p_low = np.arange(0.4,0.61,0.05)\n",
    "\n",
    "# Constraining guesses of means of low and high distributions based on observed behaviour in figure shown above. \n",
    "\n",
    "neg_ll_array = np.zeros((len(guess_low_mean), len(guess_high_mean),\n",
    "                         len(guess_sigma), len(guess_sensory_sigma), \n",
    "                         len(guess_p_back), len(guess_p_low)))\n",
    "for lm in tqdm(range(len(guess_low_mean))):\n",
    "    for hm in tqdm(range(len(guess_high_mean)), leave=False, desc=\"High mean\"):\n",
    "        for s in range(len(guess_sigma)):\n",
    "            for ss in range(len(guess_sensory_sigma)):\n",
    "                for pb in range(len(guess_p_back)):\n",
    "                    for pl in range(len(guess_p_low)):\n",
    "                        params = [guess_low_mean[lm], guess_high_mean[hm], guess_sigma[s], \\\n",
    "                                  guess_sensory_sigma[ss], guess_p_back[pb], guess_p_low[pl]]\n",
    "                        # print(lm, hm, pb)\n",
    "                        neg_ll_array[lm,hm,s,ss,pb,pl],_ = MLE(params) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Means and p_back corresponding to the least negative log likelihood value\n",
    "\"\"\"\n",
    "idxs = np.where(neg_ll_array == np.amin(neg_ll_array)) \n",
    "best_thetas = np.array([guess_low_mean[idxs[0]], guess_high_mean[idxs[1]], guess_sigma[idxs[2]], \\\n",
    "                        guess_sensory_sigma[idxs[3]], guess_p_back[idxs[4]], guess_p_low[idxs[5]]])\n",
    "print(best_thetas, np.amin(neg_ll_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define mle function\n",
    "def MLE_fmin(params):\n",
    "    log_prior_low_mean, log_prior_high_mean, log_prior_sigma, sigma_sensory, prob_back, prob_low = \\\n",
    "    params[0], params[1], params[2], params[3], params[4], params[5] # inputs are guesses at our parameters  \n",
    "    \n",
    "    _,_,LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow = \\\n",
    "    posterior_array(log_freq_seq_array, n_tones=len(trial_tones[0]), p_back=prob_back,\n",
    "                    log_prior=[log_prior_low_mean,log_prior_high_mean,log_prior_sigma])\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),len(log_freq_percept),len(log_freq_percept)))\n",
    "    \n",
    "    for itrue1 in range(len(log_freq_seq_array)):\n",
    "        for itrue2 in range(len(log_freq_seq_array)):            \n",
    "            for itrue3 in range(len(log_freq_seq_array)):\n",
    "                probPerceptgivenLatentTones = Tones3dgrid([log_freq_seq_array[itrue1],\n",
    "                                                           log_freq_seq_array[itrue2],\n",
    "                                                           log_freq_seq_array[itrue3]],sigma=sigma_sensory)                                                           \n",
    "                LikelihoodPerceptgivenHigh \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1,itrue2,itrue3]\n",
    "                LikelihoodPerceptgivenLow \\\n",
    "                += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1,itrue2,itrue3]\n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*(prob_low))\n",
    "        \n",
    "    neg_ll = 0; \n",
    "    probability_high = np.zeros((len(trial_tones),1))\n",
    "    for i_trial in range(len(trial_tones)):\n",
    "        input_array_mat = Tones3dgrid(np.array([np.log10(trial_tones[i_trial][0]),\n",
    "                                               np.log10(trial_tones[i_trial][1]),\n",
    "                                               np.log10(trial_tones[i_trial][2])]),sigma=sigma_sensory)\n",
    "        probability_high0 = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "        probability_high[i_trial] = np.sum(np.multiply(probHighgivenPercept>0.5,input_array_mat))\n",
    "            \n",
    "        if trial_behaviour[i_trial]:\n",
    "            if np.isnan(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(probability_high0 + 0.0000001)) \\\n",
    "            or np.isnan(np.log(1-probability_high0 + 0.0000001)) \\\n",
    "            or np.isinf(np.log(1-probability_high0 + 0.0000001)):\n",
    "                pdb.set_trace()\n",
    "            neg_ll += -np.log(probability_high0 + 0.0000001) # if high dist is chosen by observer\n",
    "        else:\n",
    "            neg_ll += -np.log(1 - probability_high0 + 0.0000001) # if low dist is chosen by observer\n",
    "    print(params, neg_ll)\n",
    "    return(neg_ll)\n",
    "\n",
    "\"\"\"\n",
    "Optimization using neadler mead method and a simplex algorithm\n",
    "\"\"\"\n",
    "minimum_nll = scipy.optimize.fmin(MLE_fmin, [2.55,2.85,0.1,0.28,0.3,0.51], maxiter=10000, maxfun=10000, \n",
    "                                  xtol=0.01, ftol=0.01)\n",
    "\n",
    "print(minimum_nll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

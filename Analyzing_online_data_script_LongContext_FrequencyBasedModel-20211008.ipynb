{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecc8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import scipy\n",
    "from scipy.optimize import minimize, fmin\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8387087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Obtaining data from a given expt\n",
    "\"\"\"\n",
    "csv_test = pd.read_csv('../auditory_categorization_longHigh/important_things_not_included_in_assets/allTrials.csv')\n",
    "csv_data = pd.read_csv('auditory_categorization_Hc_online_data/auditory_categorization_v3_143976_2021-10-06_15h15.21_031e0522-8d05-4b73-8d13-954610a13f6f/60a3c37fb7414cf62b79e21e_categorization_task_longHigh_2021-06-16_22h13.55.728.csv');\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7702631",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tones = 3\n",
    "n_trials = csv_data.shape[0]-47\n",
    "\n",
    "\"\"\"\n",
    "Get tones and values of keys pressed\n",
    "\"\"\"\n",
    "test_columns = list(csv_test.columns)\n",
    "test_tones_name = test_columns.index('Name')\n",
    "test_tones_col_idx = test_columns.index('Tones')\n",
    "df_names = (csv_test.iloc[0:800,test_tones_name]).values\n",
    "df_tones = (csv_test.iloc[0:800,test_tones_col_idx]).values\n",
    "\n",
    "tones_array_orig = np.zeros((n_trials,n_tones))\n",
    "tones_array_idxs_keep = []\n",
    "\n",
    "for i_wav in range(804):\n",
    "    if isinstance(csv_data['Name'][i_wav+46],str):\n",
    "        tones_array_orig[i_wav,:] = np.array(df_tones[np.where(csv_data['Name'][i_wav+46]\\\n",
    "                                                          ==df_names)[0]][0][1:-1].split(',')).astype(float)  \n",
    "        tones_array_idxs_keep += [i_wav]\n",
    "\n",
    "        \n",
    "df_tones = np.copy(tones_array_orig[tones_array_idxs_keep,:])\n",
    "df_corrans = np.copy(csv_data['corrAns'][46:csv_data.shape[0]])[tones_array_idxs_keep]\n",
    "df_keys = np.copy(csv_data['test_resp.keys'][46:csv_data.shape[0]])[tones_array_idxs_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc326e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not respond to:  [ 86 130 144 232 280 334 338 420 421 424 433 444 494 542 543 544 575 592\n",
      " 593 596 597 624 625 626 627 628 638 648 688 693 712 736 747 749 755 769\n",
      " 782]\n",
      "Got correct:  0.6175\n",
      "Got high correct:  0.7614035087719299\n",
      "Got low correct:  0.2608695652173913\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find no response cases in the expt\n",
    "\"\"\"\n",
    "no_response = np.intersect1d(np.where(df_keys!='h')[0],np.where(df_keys!='l')[0])\n",
    "print(\"Did not respond to: \",no_response)\n",
    "\n",
    "\"\"\"\n",
    "Convert keys ['l','h'] to [0,1] and calculate accuracies\n",
    "\"\"\"\n",
    "corrans_num_orig = np.zeros_like(df_corrans)\n",
    "corrans_num_orig[df_corrans == 'h'] = 1\n",
    "\n",
    "keys_num_orig = np.zeros_like(df_keys)\n",
    "keys_num_orig[df_keys == 'h'] = 1\n",
    "\n",
    "corrans_num = corrans_num_orig[:800]\n",
    "keys_num = keys_num_orig[:800]\n",
    "tones_array = df_tones[:800]\n",
    "print(\"Got correct: \", np.sum(keys_num==corrans_num)/len(tones_array))\n",
    "print(\"Got high correct: \", np.sum((keys_num)*(corrans_num))/np.sum(corrans_num))\n",
    "print(\"Got low correct: \", np.sum((1-keys_num)*(1-corrans_num))/np.sum(1-corrans_num))\n",
    "\n",
    "\"\"\"\n",
    "Subsample the long context expt with a high category bias\n",
    "\"\"\"\n",
    "def subsampleLongContext(trial_behaviour_full, corrans_full, trial_tones_full):\n",
    "    idxHigh = np.arange(len(trial_behaviour_full[0:]))[corrans_full[0:]==1]\n",
    "    idxLow = np.arange(len(trial_behaviour_full[0:]))[corrans_full[0:]==0]\n",
    "    idxOfSmallerCategory = np.random.choice(idxHigh,size=len(idxLow),replace=False)\n",
    "    idxToKeep = np.concatenate((idxLow, idxOfSmallerCategory))\n",
    "    corrans_expt = corrans_full[0:][idxToKeep]\n",
    "    trial_behaviour_expt = trial_behaviour_full[0:][idxToKeep]\n",
    "    trial_tones_expt = trial_tones_full[0:][idxToKeep,:]\n",
    "    #print(\"Got correct: \", np.sum(trial_behaviour_expthc==corrans_expthc)/len(trial_tones_expthc))\n",
    "    return trial_tones_expt, trial_behaviour_expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6d700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has been changed to check how values change with observer responses\n",
    "\n",
    "expt_tones = np.arange(90,3000,1) #array of possible true tones\n",
    "log_freq_seq_array = np.arange(0.6,4.7,0.1)\n",
    "log_freq_percept = np.arange(0.6,4.7,0.1) # array of possible perceptual tones\n",
    "\n",
    "idxs_with_response = np.delete(np.arange(len(tones_array)),no_response)\n",
    "trialTones = tones_array[idxs_with_response,:]\n",
    "trialBehaviour = keys_num[idxs_with_response]\n",
    "corrAns = corrans_num[idxs_with_response]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4554bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mean, sigma):\n",
    "    return np.exp(-(x-mean)**2/(2*sigma**2))\n",
    "\n",
    "def Tones1dgrid(latentTone, sigma):    \n",
    "    \n",
    "    input_array = gaussian(log_freq_percept, latentTone, sigma)\n",
    "    s0 = 1/np.sum(input_array)\n",
    "    input_array *= s0\n",
    "        \n",
    "    return input_array\n",
    "\n",
    "def posterior_array(freq_input, n_tones, p_back, p_low, log_prior):\n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "    freq_input - range of all possible frequencies (percepts?)\n",
    "    p_back - prob of background\n",
    "    p_low - prob of low condition\n",
    "    log_prior - list of prior parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    log_prior_low_mean = log_prior[0]; log_prior_low_sigma = log_prior[2];\n",
    "    log_prior_high_mean = log_prior[1]; log_prior_high_sigma = log_prior[2];\n",
    "    prior_low = gaussian(x=freq_input, mean=log_prior_low_mean, sigma=log_prior_low_sigma)\n",
    "    prior_high = gaussian(x=freq_input, mean=log_prior_high_mean, sigma=log_prior_high_sigma)\n",
    "    prior_dist_mixed_high = p_back*(1/len(freq_input)) + (1-p_back)*prior_high \\\n",
    "    #mixture model with p(T|B) = 1/no. of possible freqs\n",
    "    prior_dist_mixed_high /= prior_dist_mixed_high.sum() #normalizing\n",
    "    prior_dist_mixed_high = np.expand_dims(prior_dist_mixed_high, axis = 1)\n",
    "    prior_dist_mixed_low = p_back*(1/len(freq_input)) + (1-p_back)*prior_low \\\n",
    "    #mixture model with p(T|B) = 1/no. of possible freqs\n",
    "    prior_dist_mixed_low /= prior_dist_mixed_low.sum() #normalizing\n",
    "    prior_dist_mixed_low = np.expand_dims(prior_dist_mixed_low, axis = 1)\n",
    "        \n",
    "    if n_tones == 3:\n",
    "        prior_tones_low = np.expand_dims(prior_dist_mixed_low@np.transpose\\\n",
    "                                         (prior_dist_mixed_low),axis=2)@np.transpose(prior_dist_mixed_low) \\\n",
    "        #p(T1,T2..|L) \n",
    "        prior_tones_high = np.expand_dims(prior_dist_mixed_high@np.transpose\\\n",
    "                                          (prior_dist_mixed_high),axis=2)@np.transpose(prior_dist_mixed_high) \\\n",
    "        #p(T1,T2..|H) \n",
    "    elif n_tones == 1:\n",
    "        prior_tones_low = prior_dist_mixed_low\n",
    "        prior_tones_high = prior_dist_mixed_high\n",
    "        \n",
    "    normalizer = (1-p_low)*prior_tones_high + p_low*prior_tones_low #p(H)*p(T1,T2..|H) + p(L)*p(T1,T2..|L)\n",
    "    posterior = prior_tones_high*(1-p_low)/normalizer\n",
    "    # posterior /= np.sum(posterior)\n",
    "    \n",
    "    return prior_dist_mixed_high, prior_dist_mixed_low, prior_tones_high, prior_tones_low, normalizer, posterior\n",
    "\n",
    "# define mle function\n",
    "def MLE(params,trial_tones,trial_behaviour):\n",
    "    log_prior_low_mean, log_prior_high_mean, log_prior_sigma, sigma_sensory, prob_back, prob_low = \\\n",
    "    params[0], params[1], params[2], params[3], params[4], params[5] # inputs are guesses at our parameters \n",
    "    \n",
    "    reps = 1000\n",
    "    all_trial_tones = np.empty((len(trial_tones)*reps,n_tones))\n",
    "    all_trial_behaviour = np.empty((len(trial_tones)*reps,1))\n",
    "    prob_trial_behaviour = np.empty((len(trial_tones),1))\n",
    "    probability_sim_high = np.zeros((len(trial_tones),1))\n",
    "    neg_ll = 0\n",
    "\n",
    "    _,_,LikelihoodLatentTonegivenHigh,LikelihoodLatentTonegivenLow,_,_ = posterior_array(log_freq_seq_array, \n",
    "                                                                                         n_tones=1, \n",
    "                                                                                         p_low=prob_low,\n",
    "                                                                                         p_back = prob_back,\n",
    "                                                                                         log_prior=[log_prior_low_mean,\n",
    "                                                                                                    log_prior_high_mean,\n",
    "                                                                                                    log_prior_sigma])\n",
    "\n",
    "    LikelihoodPerceptgivenHigh = np.zeros((len(log_freq_percept),))\n",
    "    LikelihoodPerceptgivenLow = np.zeros((len(log_freq_percept),))\n",
    "\n",
    "    for itrue1 in range(len(log_freq_percept)):\n",
    "        probPerceptgivenLatentTones = Tones1dgrid(latentTone=log_freq_percept[itrue1],sigma=sigma_sensory)\n",
    "        LikelihoodPerceptgivenHigh += probPerceptgivenLatentTones * LikelihoodLatentTonegivenHigh[itrue1]\n",
    "        LikelihoodPerceptgivenLow += probPerceptgivenLatentTones * LikelihoodLatentTonegivenLow[itrue1]\n",
    "        \n",
    "    probHighgivenPercept = LikelihoodPerceptgivenHigh*(1-prob_low)/\\\n",
    "    (LikelihoodPerceptgivenHigh*(1-prob_low) + LikelihoodPerceptgivenLow*prob_low)\n",
    "\n",
    "    for i_stim in range(len(trial_tones)):\n",
    "        input_array_mat = np.random.normal(loc=np.log10(trial_tones[i_stim]),\n",
    "                                           scale=sigma_sensory,\n",
    "                                           size=(reps,1,n_tones)) \n",
    "        #pick tones from the gaussian with mean as log(true_tone) and sensory sigma 0.1    \n",
    "        for i_tperc in range(reps):\n",
    "            perc_tone_idxs = np.zeros((n_tones,1),dtype=int)\n",
    "            for i in range(n_tones):\n",
    "                # find relevant adjacent freq percepts   \n",
    "                perc_tone_idxs[i] = np.argmin(np.abs(log_freq_percept-input_array_mat[i_tperc][0][i]))  \n",
    "            # the suboptimal subject choses the highest frequency they hear for categorization\n",
    "            posterior_perc_tone = probHighgivenPercept[np.max(perc_tone_idxs)]\n",
    "            # this makes the same choice for one tone percept every time that tone is perceived  \n",
    "            trial_behaviour_generated = np.squeeze(posterior_perc_tone) > 0.5 \n",
    "            all_trial_behaviour[i_stim*reps+i_tperc,:] = trial_behaviour_generated\n",
    "        all_trial_tones[i_stim*reps:(i_stim+1)*reps,:] = trial_tones[i_stim]    \n",
    "        prob_trial_behaviour[i_stim] = np.mean(all_trial_behaviour[i_stim*reps:(i_stim+1)*reps])\n",
    "        \n",
    "        if trial_behaviour[i_stim]:\n",
    "            if np.isnan(np.log(prob_trial_behaviour[i_stim] + 0.0000001)) \\\n",
    "            or np.isinf(np.log(prob_trial_behaviour[i_stim] + 0.0000001)) \\\n",
    "            or np.isnan(np.log(1-prob_trial_behaviour[i_stim] + 0.0000001)) \\\n",
    "            or np.isinf(np.log(1-prob_trial_behaviour[i_stim] + 0.0000001)):\n",
    "                pdb.set_trace()\n",
    "            neg_ll += -np.log(prob_trial_behaviour[i_stim] + 0.0000001) # if high dist is chosen by observer\n",
    "        else:\n",
    "            neg_ll += -np.log(1-prob_trial_behaviour[i_stim] + 0.0000001) # if low dist is chosen by observer\n",
    "    #print(params, neg_ll)        \n",
    "    return(neg_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ef4f6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 3) (434,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9056d6bcc43343eebe8135d2076c68c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-25050ae6b1f2>:46: RuntimeWarning: invalid value encountered in true_divide\n",
      "  posterior = prior_tones_high*(1-p_low)/normalizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.6962486514917 [[2.7 ]\n",
      " [2.7 ]\n",
      " [0.85]\n",
      " [0.15]\n",
      " [0.  ]\n",
      " [0.5 ]]\n",
      "(434, 3) (434,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01335997fef44006be6d425c1da9bc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486.6330022580963 [[2.7 ]\n",
      " [2.7 ]\n",
      " [0.85]\n",
      " [0.15]\n",
      " [0.  ]\n",
      " [0.5 ]]\n",
      "(434, 3) (434,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90ab6b1b6d94af1b854b47e66b11327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486.2736464183019 [[2.7 ]\n",
      " [2.7 ]\n",
      " [0.85]\n",
      " [0.15]\n",
      " [0.  ]\n",
      " [0.5 ]]\n",
      "(434, 3) (434,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aa823db11841689cdec6ee62dadcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806e7bd469be4ca18b88ff5cebf0ebf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "High mean:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d77fd86ed0d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                       guess_sensory_sigma[ss], guess_p_back[pb], guess_p_low[pl]]\n\u001b[1;32m     31\u001b[0m                             \u001b[0;31m# print(lm, hm, pb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                             neg_ll_array[lm,hm,s,ss,pb,pl] = MLE(params,\n\u001b[0m\u001b[1;32m     33\u001b[0m                                                                 \u001b[0mtrial_tones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrialTones_subsampled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                                 trial_behaviour=trialBehaviour_subsampled)                                        \n",
      "\u001b[0;32m<ipython-input-6-25050ae6b1f2>\u001b[0m in \u001b[0;36mMLE\u001b[0;34m(params, trial_tones, trial_behaviour)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mposterior_perc_tone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobHighgivenPercept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperc_tone_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# this makes the same choice for one tone percept every time that tone is perceived\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mtrial_behaviour_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior_perc_tone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mall_trial_behaviour\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_stim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi_tperc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_behaviour_generated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mall_trial_tones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_stim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_stim\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_tones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_stim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/glm/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \"\"\"\n\u001b[0;32m-> 1499\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m         \u001b[0msqueeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "New optimization algorithm: uses scipy.optimize.fmin. \n",
    "Crude grid initially and then find minimum using the function.\n",
    "\n",
    "Then p_low value corresponding to the least negative log likelihood measurement is found.\n",
    "\"\"\"\n",
    "\n",
    "# Sigma sensory value is based on the no context simple trial fitting.\n",
    "guess_low_mean = np.arange(2.1,2.71,0.15); guess_high_mean = np.arange(2.7,3.31,0.15); \n",
    "guess_sigma = np.arange(0.05,1,0.2); guess_sensory_sigma = np.array([0.15]);\n",
    "guess_p_back = np.array([0]); guess_p_low =np.arange(0.1,1.1,0.1);\n",
    "\n",
    "# Constraining guesses of means of low and high distributions based on observed behaviour in figure shown above. \n",
    "\n",
    "for iSubsampled in range(4):\n",
    "    trialTones_subsampled, trialBehaviour_subsampled = subsampleLongContext(trial_behaviour_full=trialBehaviour, \n",
    "                                                                            corrans_full=corrAns,\n",
    "                                                                            trial_tones_full=trialTones)\n",
    "    print(trialTones_subsampled.shape, trialBehaviour_subsampled.shape)\n",
    "    \n",
    "    neg_ll_array = np.zeros((len(guess_low_mean), len(guess_high_mean), len(guess_sigma), \n",
    "                             len(guess_sensory_sigma), len(guess_p_back), len(guess_p_low)))\n",
    "    for lm in tqdm(range(len(guess_low_mean))):\n",
    "        for hm in tqdm(range(len(guess_high_mean)), leave=False, desc=\"High mean\"):\n",
    "            for s in range(len(guess_sigma)):\n",
    "                for ss in range(len(guess_sensory_sigma)):\n",
    "                    for pb in range(len(guess_p_back)):\n",
    "                        for pl in range(len(guess_p_low)):\n",
    "                            params = [guess_low_mean[lm], guess_high_mean[hm], guess_sigma[s], \n",
    "                                      guess_sensory_sigma[ss], guess_p_back[pb], guess_p_low[pl]]\n",
    "                            # print(lm, hm, pb)\n",
    "                            neg_ll_array[lm,hm,s,ss,pb,pl] = MLE(params,\n",
    "                                                                trial_tones=trialTones_subsampled,\n",
    "                                                                trial_behaviour=trialBehaviour_subsampled)                                        \n",
    "            \n",
    "    idxs = np.where(neg_ll_array == np.amin(neg_ll_array)) \n",
    "    best_thetas = np.array([guess_low_mean[idxs[0]], guess_high_mean[idxs[1]], guess_sigma[idxs[2]], \\\n",
    "                            guess_sensory_sigma[idxs[3]], guess_p_back[idxs[4]], guess_p_low[idxs[5]]])\n",
    "\n",
    "    print(np.amin(neg_ll_array),best_thetas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(neg_ll_array == np.amin(neg_ll_array)) \n",
    "best_thetas = np.array([guess_low_mean[idxs[0]], guess_high_mean[idxs[1]], guess_sigma[idxs[2]], \\\n",
    "                        guess_sensory_sigma[idxs[3]], guess_p_back[idxs[4]], guess_p_low[idxs[5]]])\n",
    "\n",
    "print(np.amin(neg_ll_array),best_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-version",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
